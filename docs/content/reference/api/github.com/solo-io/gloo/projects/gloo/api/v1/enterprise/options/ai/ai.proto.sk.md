
---
title: "ai.proto"
weight: 5
---

<!-- Code generated by solo-kit. DO NOT EDIT. -->


### Package: `ai.options.gloo.solo.io` 
#### Types:


- [SingleAuthToken](#singleauthtoken)
- [UpstreamSpec](#upstreamspec)
- [CustomHost](#customhost)
- [OpenAI](#openai)
- [Mistral](#mistral)
- [Anthropic](#anthropic)
- [RouteSettings](#routesettings)
- [FieldDefault](#fielddefault)
- [Postgres](#postgres)
- [Embedding](#embedding)
- [OpenAI](#openai)
- [SemanticCache](#semanticcache)
- [Redis](#redis)
- [DataStore](#datastore)
- [Mode](#mode)
- [RAG](#rag)
- [DataStore](#datastore)
- [RateLimiting](#ratelimiting)
- [AIPromptEnrichment](#aipromptenrichment)
- [Message](#message)
- [AIPromptGaurd](#aipromptgaurd)
- [Request](#request)
- [Response](#response)
- [BuiltIn](#builtin)
  



##### Source File: [github.com/solo-io/gloo/projects/gloo/api/v1/enterprise/options/ai/ai.proto](https://github.com/solo-io/gloo/blob/main/projects/gloo/api/v1/enterprise/options/ai/ai.proto)





---
### SingleAuthToken



```yaml
"inline": string
"secretRef": .core.solo.io.ResourceRef

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `inline` | `string` | Provide easy inline way to specify a token. Only one of `inline` or `secretRef` can be set. |
| `secretRef` | [.core.solo.io.ResourceRef](../../../../../../../../../solo-kit/api/v1/ref.proto.sk/#resourceref) | Reference to a secret in the same namespace as the Upstream. Only one of `secretRef` or `inline` can be set. |




---
### UpstreamSpec

 
The AI UpstreamSpec represents a logical LLM provider backend.
The purpose of this spec is a way to configure which backend to use
as well as how to authenticate with the backend.

Currently the options are:
- OpenAI
Default Host: api.openai.com
Default Port: 443
Auth Token: Bearer token to use for the OpenAI API
- Mistral
Default Host: api.mistral.com
Default Port: 443
Auth Token: Bearer token to use for the Mistral API
- Anthropic
Default Host: api.anthropic.com
Default Port: 443
Auth Token: x-api-key to use for the Anthropic API
Version: Optional version header to pass to the Anthropic API

All of the above backends can be configured to use a custom host and port.
This option is meant to allow users to proxy the request, or to use a different
backend altogether which is API compliant with the upstream version.

Examples:

OpenAI with inline auth token:
```
ai:
openai:
authToken:
inline: "my_token"
```

Mistral with secret ref:
```
ai:
mistral:
authToken:
secretRef:
name: "my-secret"
namespace: "my-ns"
```

Anthropic with inline token and custom Host:
```
ai:
anthropic:
authToken:
inline: "my_token"
customHost:
host: "my-anthropic-host.com"
port: 443 # Port is optional and will default to 443 for HTTPS
```

```yaml
"openai": .ai.options.gloo.solo.io.UpstreamSpec.OpenAI
"mistral": .ai.options.gloo.solo.io.UpstreamSpec.Mistral
"anthropic": .ai.options.gloo.solo.io.UpstreamSpec.Anthropic

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `openai` | [.ai.options.gloo.solo.io.UpstreamSpec.OpenAI](../ai.proto.sk/#openai) |  Only one of `openai`, `mistral`, or `anthropic` can be set. |
| `mistral` | [.ai.options.gloo.solo.io.UpstreamSpec.Mistral](../ai.proto.sk/#mistral) |  Only one of `mistral`, `openai`, or `anthropic` can be set. |
| `anthropic` | [.ai.options.gloo.solo.io.UpstreamSpec.Anthropic](../ai.proto.sk/#anthropic) |  Only one of `anthropic`, `openai`, or `mistral` can be set. |




---
### CustomHost



```yaml
"host": string
"port": int

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `host` | `string` | Custom host to send the traffic to. |
| `port` | `int` | Custom host to send the traffic to. |




---
### OpenAI

 
Settings for the OpenAI API

```yaml
"authToken": .ai.options.gloo.solo.io.SingleAuthToken
"customHost": .ai.options.gloo.solo.io.UpstreamSpec.CustomHost

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `authToken` | [.ai.options.gloo.solo.io.SingleAuthToken](../ai.proto.sk/#singleauthtoken) | Auth Token to use for the OpenAI API This token will be placed into the `Authorization` header and prefixed with Bearer if not present when sending the request to the upstream. |
| `customHost` | [.ai.options.gloo.solo.io.UpstreamSpec.CustomHost](../ai.proto.sk/#customhost) | Optional custom host to send the traffic to. |




---
### Mistral

 
Settings for the Mistral API

```yaml
"authToken": .ai.options.gloo.solo.io.SingleAuthToken
"customHost": .ai.options.gloo.solo.io.UpstreamSpec.CustomHost

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `authToken` | [.ai.options.gloo.solo.io.SingleAuthToken](../ai.proto.sk/#singleauthtoken) | Auth Token to use for the Mistral API. This token will be placed into the `Authorization` header and prefixed with Bearer if not present when sending the request to the upstream. |
| `customHost` | [.ai.options.gloo.solo.io.UpstreamSpec.CustomHost](../ai.proto.sk/#customhost) | Optional custom host to send the traffic to. |




---
### Anthropic



```yaml
"authToken": .ai.options.gloo.solo.io.SingleAuthToken
"customHost": .ai.options.gloo.solo.io.UpstreamSpec.CustomHost
"version": string

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `authToken` | [.ai.options.gloo.solo.io.SingleAuthToken](../ai.proto.sk/#singleauthtoken) | Auth Token to use for the Anthropic API. This token will be placed into the `x-api-key` header when sending the request to the upstream. |
| `customHost` | [.ai.options.gloo.solo.io.UpstreamSpec.CustomHost](../ai.proto.sk/#customhost) |  |
| `version` | `string` | An optional version header to pass to the Anthropic API See: https://docs.anthropic.com/en/api/versioning for more details. |




---
### RouteSettings

 
RouteSettings is a way to configure the behavior of the LLM provider on a per-route basis
This allows users to configure things like:
- Prompt Enrichment
- Retrieval Augmented Generation
- Semantic Caching
- Backup Models
- Defaults to merge with the user input fields
- Guardrails

NOTE: These settings may only be applied to a route which uses an LLMProvider backend!

```yaml
"promptEnrichment": .ai.options.gloo.solo.io.AIPromptEnrichment
"promptGuard": .ai.options.gloo.solo.io.AIPromptGaurd
"rag": .ai.options.gloo.solo.io.RAG
"semanticCache": .ai.options.gloo.solo.io.SemanticCache
"backupModels": []string
"defaults": []ai.options.gloo.solo.io.FieldDefault

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `promptEnrichment` | [.ai.options.gloo.solo.io.AIPromptEnrichment](../ai.proto.sk/#aipromptenrichment) | Config used to enrich the prompt. This can only be used with LLMProviders using the CHAT API type. Prompt enrichment allows you to add additional context to the prompt before sending it to the model. Unlike RAG or other dynamic context methods, prompt enrichment is static and will be applied to every request. Note: Some providers, including Anthropic do not support SYSTEM role messages, but rather have a dedicated system field in the input JSON. In this case, `field_defaults` should be used to set the system field. See the docs for that field for an example. Example: ``` promptEnrichment: prepend: - role: SYSTEM content: "answer all questions in french" append: - role: USER content: "Describe the painting as if you were a famous art critic from the 17th century" ```. |
| `promptGuard` | [.ai.options.gloo.solo.io.AIPromptGaurd](../ai.proto.sk/#aipromptgaurd) | Guards to apply to the LLM requests on this route. This can be used to reject requests based on the content of the prompt, as well as mask responses based on the content of the response. These guards can be also be used at the same time. Below is a simple example of a prompt guard that will reject any prompt that contains the string "credit card" and will mask any credit card numbers in the response. ``` promptGuard: request: customResponseMessage: "Rejected due to inappropriate content" matches: - "credit card" response: matches: # Mastercard - '(?:^|\D)(5[1-5][0-9]{2}(?:\ |\-|)[0-9]{4}(?:\ |\-|)[0-9]{4}(?:\ |\-|)[0-9]{4})(?:\D|$)' ````. |
| `rag` | [.ai.options.gloo.solo.io.RAG](../ai.proto.sk/#rag) | Retrieval Augmented Generation. https://research.ibm.com/blog/retrieval-augmented-generation-RAG Retrieval Augmented Generation is a process by which you "augment" the information a model has access to by providing it with a set of documents to use as context. This can be used to improve the quality of the generated text. Important Note: The same embedding mechanism must be used for the prompt which was used for the initial creation of the context documents. Example using postgres for storage and OpenAI for embedding: ``` rag: datastore: postgres: connectionString: postgresql+psycopg://gloo:gloo@172.17.0.1:6024/gloo collectionName: default embedding: openai: authToken: secretRef: name: openai-secret namespace: gloo-system ```. |
| `semanticCache` | [.ai.options.gloo.solo.io.SemanticCache](../ai.proto.sk/#semanticcache) | Semantic caching configuration Semantic caching allows you to cache previous model responses in order to provide faster responses to similar requests in the future. Results will vary depending on the embedding mechanism used, as well as the similarity threshold set. Example using Redis for storage and OpenAI for embedding: ``` semanticCache: datastore: redis: connectionString: redis://172.17.0.1:6379 embedding: openai: authToken: secretRef: name: openai-secret namespace: gloo-system ```. |
| `backupModels` | `[]string` | Backup models to use in case of a failure with the primary model passed in the request. By default each model will be tried 2 times before moving on to the next model in the list. If all requests fail then the final response will be returned to the client. |
| `defaults` | [[]ai.options.gloo.solo.io.FieldDefault](../ai.proto.sk/#fielddefault) | A list of defaults to be merged with the user input fields. These will NOT override the user input fields unless override is explicitly set to true. Some examples include setting the temperature, max_tokens, etc. Example overriding system field for Anthropic: ``` # Anthropic doesn't support a system chat type defaults: - field: "system" value: "answer all questions in french" ``` Example setting the temperature and max_tokens, overriding max_tokens: ``` defaults: - field: "temperature" value: 0.5 - field: "max_tokens" value: 100 ```. |




---
### FieldDefault



```yaml
"field": string
"value": .google.protobuf.Value
"override": bool

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `field` | `string` | Field name. |
| `value` | [.google.protobuf.Value](https://developers.google.com/protocol-buffers/docs/reference/csharp/class/google/protobuf/well-known-types/value) | Field Value, this can be any valid JSON value. |
| `override` | `bool` | Whether or not to override the field if it already exists. |




---
### Postgres



```yaml
"connectionString": string
"collectionName": string

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `connectionString` | `string` | Connection string to the Postgres database. |
| `collectionName` | `string` | Name of the table to use. |




---
### Embedding



```yaml
"openai": .ai.options.gloo.solo.io.Embedding.OpenAI

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `openai` | [.ai.options.gloo.solo.io.Embedding.OpenAI](../ai.proto.sk/#openai) |  |




---
### OpenAI



```yaml
"authToken": .ai.options.gloo.solo.io.SingleAuthToken

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `authToken` | [.ai.options.gloo.solo.io.SingleAuthToken](../ai.proto.sk/#singleauthtoken) |  |




---
### SemanticCache



```yaml
"datastore": .ai.options.gloo.solo.io.SemanticCache.DataStore
"embedding": .ai.options.gloo.solo.io.Embedding
"ttl": int
"mode": .ai.options.gloo.solo.io.SemanticCache.Mode

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `datastore` | [.ai.options.gloo.solo.io.SemanticCache.DataStore](../ai.proto.sk/#datastore) | Which data store to use. |
| `embedding` | [.ai.options.gloo.solo.io.Embedding](../ai.proto.sk/#embedding) | Model to use to get embeddings for prompt. |
| `ttl` | `int` | Time before data in the cache is considered expired. |
| `mode` | [.ai.options.gloo.solo.io.SemanticCache.Mode](../ai.proto.sk/#mode) | Cache mode to use: READ_WRITE or READ_ONLY. |




---
### Redis



```yaml
"connectionString": string
"scoreThreshold": float

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `connectionString` | `string` | Connection string to the Redis database. |
| `scoreThreshold` | `float` | Similarity score threshold value between 0.0 and 1.0 that determines how similar two queries need to be in order to return a cached result. The lower the number, the more similar the queries need to be for a cache hit. +kubebuilder:validation:Minimum=0 +kubebuilder:validation:Maximum=1. |




---
### DataStore

 
Data store from which to cache the request/response pairs

```yaml
"redis": .ai.options.gloo.solo.io.SemanticCache.Redis

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `redis` | [.ai.options.gloo.solo.io.SemanticCache.Redis](../ai.proto.sk/#redis) |  |




---
### Mode



| Name | Description |
| ----- | ----------- | 
| `READ_WRITE` | Read and write to the cache as a part of the request/response lifecycle |
| `READ_ONLY` | Only read from the cache, do not write to it. Data will be written to the cache outside the request/response cycle. |




---
### RAG



```yaml
"datastore": .ai.options.gloo.solo.io.RAG.DataStore
"embedding": .ai.options.gloo.solo.io.Embedding
"promptTemplate": string

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `datastore` | [.ai.options.gloo.solo.io.RAG.DataStore](../ai.proto.sk/#datastore) | Data store from which to fetch the embeddings. |
| `embedding` | [.ai.options.gloo.solo.io.Embedding](../ai.proto.sk/#embedding) | Model to use to get embeddings for prompt. |
| `promptTemplate` | `string` | Template to use to embed the returned context. |




---
### DataStore



```yaml
"postgres": .ai.options.gloo.solo.io.Postgres

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `postgres` | [.ai.options.gloo.solo.io.Postgres](../ai.proto.sk/#postgres) |  |




---
### RateLimiting



```yaml
"rateLimitConfigs": []string

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `rateLimitConfigs` | `[]string` | List of rate_limit configs to apply. |




---
### AIPromptEnrichment



```yaml
"prepend": []ai.options.gloo.solo.io.AIPromptEnrichment.Message
"append": []ai.options.gloo.solo.io.AIPromptEnrichment.Message

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `prepend` | [[]ai.options.gloo.solo.io.AIPromptEnrichment.Message](../ai.proto.sk/#message) | A list of messages to be prepended to the prompt sent by the client. |
| `append` | [[]ai.options.gloo.solo.io.AIPromptEnrichment.Message](../ai.proto.sk/#message) | A list of messages to be appended to the prompt sent by the client. |




---
### Message



```yaml
"role": string
"content": string

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `role` | `string` | Role of the message. The available roles depend on the backend model being used, please consult the documentation for more information. |
| `content` | `string` | String content of the message. |




---
### AIPromptGaurd



```yaml
"request": .ai.options.gloo.solo.io.AIPromptGaurd.Request
"response": .ai.options.gloo.solo.io.AIPromptGaurd.Response

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `request` | [.ai.options.gloo.solo.io.AIPromptGaurd.Request](../ai.proto.sk/#request) | Guards for the prompt request. |
| `response` | [.ai.options.gloo.solo.io.AIPromptGaurd.Response](../ai.proto.sk/#response) | Guards for the LLM response. |




---
### Request



```yaml
"matches": []string
"customResponseMessage": string

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `matches` | `[]string` | A list of Regex patterns to match against the prompt. Each one will be checked against the prompt and if any match the request will be rejected. |
| `customResponseMessage` | `string` | Custom response message to send back to the client. If not specified, the following default message will be used: "The request was rejected due to inappropriate content". |




---
### Response



```yaml
"matches": []string
"builtins": []ai.options.gloo.solo.io.AIPromptGaurd.Response.BuiltIn

```

| Field | Type | Description |
| ----- | ---- | ----------- | 
| `matches` | `[]string` | A list of Regex patterns to match against the response. All matches will be masked before being sent back to the client. matches and builtins are additive. |
| `builtins` | [[]ai.options.gloo.solo.io.AIPromptGaurd.Response.BuiltIn](../ai.proto.sk/#builtin) | A list of built-in regexes to mask in the response. matches and builtins are additive. |




---
### BuiltIn



| Name | Description |
| ----- | ----------- | 
| `SSN` | Default REGEX for Social Security Numbers |
| `CREDIT_CARD` | Default REGEX for Credit Card Numbers |
| `EMAIL` | Default REGEX for Email Addresses |
| `PHONE_NUMBER` | Default REGEX for Phone Numbers |





<!-- Start of HubSpot Embed Code -->
<script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/5130874.js"></script>
<!-- End of HubSpot Embed Code -->
