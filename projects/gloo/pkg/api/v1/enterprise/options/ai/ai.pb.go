// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        v3.6.1
// source: github.com/solo-io/gloo/projects/gloo/api/v1/enterprise/options/ai/ai.proto

package ai

import (
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"

	_ "github.com/solo-io/protoc-gen-ext/extproto"
	core "github.com/solo-io/solo-kit/pkg/api/v1/resources/core"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	structpb "google.golang.org/protobuf/types/known/structpb"
	wrapperspb "google.golang.org/protobuf/types/known/wrapperspb"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type ApiJsonSchema int32

const (
	ApiJsonSchema_NOT_SET   ApiJsonSchema = 0
	ApiJsonSchema_ANTHROPIC ApiJsonSchema = 1
	ApiJsonSchema_GEMINI    ApiJsonSchema = 2
	ApiJsonSchema_OPENAI    ApiJsonSchema = 3
)

// Enum value maps for ApiJsonSchema.
var (
	ApiJsonSchema_name = map[int32]string{
		0: "NOT_SET",
		1: "ANTHROPIC",
		2: "GEMINI",
		3: "OPENAI",
	}
	ApiJsonSchema_value = map[string]int32{
		"NOT_SET":   0,
		"ANTHROPIC": 1,
		"GEMINI":    2,
		"OPENAI":    3,
	}
)

func (x ApiJsonSchema) Enum() *ApiJsonSchema {
	p := new(ApiJsonSchema)
	*p = x
	return p
}

func (x ApiJsonSchema) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ApiJsonSchema) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[0].Descriptor()
}

func (ApiJsonSchema) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[0]
}

func (x ApiJsonSchema) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ApiJsonSchema.Descriptor instead.
func (ApiJsonSchema) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{0}
}

// The type of publisher model to use. Currently, only Google is supported.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_VertexAI_Publisher int32

const (
	UpstreamSpec_VertexAI_GOOGLE UpstreamSpec_VertexAI_Publisher = 0
)

// Enum value maps for UpstreamSpec_VertexAI_Publisher.
var (
	UpstreamSpec_VertexAI_Publisher_name = map[int32]string{
		0: "GOOGLE",
	}
	UpstreamSpec_VertexAI_Publisher_value = map[string]int32{
		"GOOGLE": 0,
	}
)

func (x UpstreamSpec_VertexAI_Publisher) Enum() *UpstreamSpec_VertexAI_Publisher {
	p := new(UpstreamSpec_VertexAI_Publisher)
	*p = x
	return p
}

func (x UpstreamSpec_VertexAI_Publisher) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (UpstreamSpec_VertexAI_Publisher) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[1].Descriptor()
}

func (UpstreamSpec_VertexAI_Publisher) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[1]
}

func (x UpstreamSpec_VertexAI_Publisher) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use UpstreamSpec_VertexAI_Publisher.Descriptor instead.
func (UpstreamSpec_VertexAI_Publisher) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 4, 0}
}

// The type of route to the LLM provider API.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type RouteSettings_RouteType int32

const (
	// The LLM generates the full response before responding to a client.
	RouteSettings_CHAT RouteSettings_RouteType = 0
	// Stream responses to a client, which allows the LLM to stream out tokens as they are generated.
	RouteSettings_CHAT_STREAMING RouteSettings_RouteType = 1
)

// Enum value maps for RouteSettings_RouteType.
var (
	RouteSettings_RouteType_name = map[int32]string{
		0: "CHAT",
		1: "CHAT_STREAMING",
	}
	RouteSettings_RouteType_value = map[string]int32{
		"CHAT":           0,
		"CHAT_STREAMING": 1,
	}
)

func (x RouteSettings_RouteType) Enum() *RouteSettings_RouteType {
	p := new(RouteSettings_RouteType)
	*p = x
	return p
}

func (x RouteSettings_RouteType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (RouteSettings_RouteType) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[2].Descriptor()
}

func (RouteSettings_RouteType) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[2]
}

func (x RouteSettings_RouteType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use RouteSettings_RouteType.Descriptor instead.
func (RouteSettings_RouteType) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{2, 0}
}

// The caching mode to use for the request and response lifecycle.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type SemanticCache_Mode int32

const (
	// Read and write to the cache as a part of the request and response lifecycle.
	SemanticCache_READ_WRITE SemanticCache_Mode = 0
	// Only read from the cache, and do not write to it.
	// Data is written to the cache outside of the request and response cycle.
	SemanticCache_READ_ONLY SemanticCache_Mode = 1
)

// Enum value maps for SemanticCache_Mode.
var (
	SemanticCache_Mode_name = map[int32]string{
		0: "READ_WRITE",
		1: "READ_ONLY",
	}
	SemanticCache_Mode_value = map[string]int32{
		"READ_WRITE": 0,
		"READ_ONLY":  1,
	}
)

func (x SemanticCache_Mode) Enum() *SemanticCache_Mode {
	p := new(SemanticCache_Mode)
	*p = x
	return p
}

func (x SemanticCache_Mode) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SemanticCache_Mode) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[3].Descriptor()
}

func (SemanticCache_Mode) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[3]
}

func (x SemanticCache_Mode) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SemanticCache_Mode.Descriptor instead.
func (SemanticCache_Mode) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{6, 0}
}

// Built-in regex patterns for specific types of strings in prompts.
// For example, if you specify `CREDIT_CARD`, any credit card numbers
// in the request or response are matched.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Regex_BuiltIn int32

const (
	// Default regex matching for Social Security numbers.
	AIPromptGuard_Regex_SSN AIPromptGuard_Regex_BuiltIn = 0
	// Default regex matching for credit card numbers.
	AIPromptGuard_Regex_CREDIT_CARD AIPromptGuard_Regex_BuiltIn = 1
	// Default regex matching for phone numbers.
	AIPromptGuard_Regex_PHONE_NUMBER AIPromptGuard_Regex_BuiltIn = 2
	// Default regex matching for email addresses.
	AIPromptGuard_Regex_EMAIL AIPromptGuard_Regex_BuiltIn = 3
)

// Enum value maps for AIPromptGuard_Regex_BuiltIn.
var (
	AIPromptGuard_Regex_BuiltIn_name = map[int32]string{
		0: "SSN",
		1: "CREDIT_CARD",
		2: "PHONE_NUMBER",
		3: "EMAIL",
	}
	AIPromptGuard_Regex_BuiltIn_value = map[string]int32{
		"SSN":          0,
		"CREDIT_CARD":  1,
		"PHONE_NUMBER": 2,
		"EMAIL":        3,
	}
)

func (x AIPromptGuard_Regex_BuiltIn) Enum() *AIPromptGuard_Regex_BuiltIn {
	p := new(AIPromptGuard_Regex_BuiltIn)
	*p = x
	return p
}

func (x AIPromptGuard_Regex_BuiltIn) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AIPromptGuard_Regex_BuiltIn) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[4].Descriptor()
}

func (AIPromptGuard_Regex_BuiltIn) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[4]
}

func (x AIPromptGuard_Regex_BuiltIn) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AIPromptGuard_Regex_BuiltIn.Descriptor instead.
func (AIPromptGuard_Regex_BuiltIn) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 0, 0}
}

// The action to take if a regex pattern is matched in a request or response.
// This setting applies only to request matches. Response matches are always masked by default.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Regex_Action int32

const (
	// Mask the matched data in the request.
	AIPromptGuard_Regex_MASK AIPromptGuard_Regex_Action = 0
	// Reject the request if the regex matches content in the request.
	AIPromptGuard_Regex_REJECT AIPromptGuard_Regex_Action = 1
)

// Enum value maps for AIPromptGuard_Regex_Action.
var (
	AIPromptGuard_Regex_Action_name = map[int32]string{
		0: "MASK",
		1: "REJECT",
	}
	AIPromptGuard_Regex_Action_value = map[string]int32{
		"MASK":   0,
		"REJECT": 1,
	}
)

func (x AIPromptGuard_Regex_Action) Enum() *AIPromptGuard_Regex_Action {
	p := new(AIPromptGuard_Regex_Action)
	*p = x
	return p
}

func (x AIPromptGuard_Regex_Action) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AIPromptGuard_Regex_Action) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[5].Descriptor()
}

func (AIPromptGuard_Regex_Action) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[5]
}

func (x AIPromptGuard_Regex_Action) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AIPromptGuard_Regex_Action.Descriptor instead.
func (AIPromptGuard_Regex_Action) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 0, 1}
}

// The header string match type.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Webhook_HeaderMatch_MatchType int32

const (
	// The string must match exactly the specified string.
	AIPromptGuard_Webhook_HeaderMatch_EXACT AIPromptGuard_Webhook_HeaderMatch_MatchType = 0
	// The string must have the specified prefix.
	AIPromptGuard_Webhook_HeaderMatch_PREFIX AIPromptGuard_Webhook_HeaderMatch_MatchType = 1
	// The string must have the specified suffix.
	AIPromptGuard_Webhook_HeaderMatch_SUFFIX AIPromptGuard_Webhook_HeaderMatch_MatchType = 2
	// The header string must contain the specified string.
	AIPromptGuard_Webhook_HeaderMatch_CONTAINS AIPromptGuard_Webhook_HeaderMatch_MatchType = 3
	// The string must match the specified [RE2-style regular expression](https://github.com/google/re2/wiki/) pattern.
	AIPromptGuard_Webhook_HeaderMatch_REGEX AIPromptGuard_Webhook_HeaderMatch_MatchType = 4
)

// Enum value maps for AIPromptGuard_Webhook_HeaderMatch_MatchType.
var (
	AIPromptGuard_Webhook_HeaderMatch_MatchType_name = map[int32]string{
		0: "EXACT",
		1: "PREFIX",
		2: "SUFFIX",
		3: "CONTAINS",
		4: "REGEX",
	}
	AIPromptGuard_Webhook_HeaderMatch_MatchType_value = map[string]int32{
		"EXACT":    0,
		"PREFIX":   1,
		"SUFFIX":   2,
		"CONTAINS": 3,
		"REGEX":    4,
	}
)

func (x AIPromptGuard_Webhook_HeaderMatch_MatchType) Enum() *AIPromptGuard_Webhook_HeaderMatch_MatchType {
	p := new(AIPromptGuard_Webhook_HeaderMatch_MatchType)
	*p = x
	return p
}

func (x AIPromptGuard_Webhook_HeaderMatch_MatchType) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AIPromptGuard_Webhook_HeaderMatch_MatchType) Descriptor() protoreflect.EnumDescriptor {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[6].Descriptor()
}

func (AIPromptGuard_Webhook_HeaderMatch_MatchType) Type() protoreflect.EnumType {
	return &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes[6]
}

func (x AIPromptGuard_Webhook_HeaderMatch_MatchType) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AIPromptGuard_Webhook_HeaderMatch_MatchType.Descriptor instead.
func (AIPromptGuard_Webhook_HeaderMatch_MatchType) EnumDescriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 1, 0, 0}
}

// The authorization token that the AI gateway uses to access the LLM provider API.
// This token is automatically sent in a request header, depending on the LLM provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type SingleAuthToken struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*SingleAuthToken_Inline
	//	*SingleAuthToken_SecretRef
	//	*SingleAuthToken_Passthrough_
	AuthTokenSource isSingleAuthToken_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *SingleAuthToken) Reset() {
	*x = SingleAuthToken{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SingleAuthToken) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SingleAuthToken) ProtoMessage() {}

func (x *SingleAuthToken) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SingleAuthToken.ProtoReflect.Descriptor instead.
func (*SingleAuthToken) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{0}
}

func (x *SingleAuthToken) GetAuthTokenSource() isSingleAuthToken_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *SingleAuthToken) GetInline() string {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*SingleAuthToken_Inline); ok {
			return x.Inline
		}
	}
	return ""
}

func (x *SingleAuthToken) GetSecretRef() *core.ResourceRef {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*SingleAuthToken_SecretRef); ok {
			return x.SecretRef
		}
	}
	return nil
}

func (x *SingleAuthToken) GetPassthrough() *SingleAuthToken_Passthrough {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*SingleAuthToken_Passthrough_); ok {
			return x.Passthrough
		}
	}
	return nil
}

type isSingleAuthToken_AuthTokenSource interface {
	isSingleAuthToken_AuthTokenSource()
}

type SingleAuthToken_Inline struct {
	// Provide the token directly in the configuration for the Upstream.
	// This option is the least secure. Only use this option for quick tests such as trying out AI Gateway.
	Inline string `protobuf:"bytes,1,opt,name=inline,proto3,oneof"`
}

type SingleAuthToken_SecretRef struct {
	// Store the API key in a Kubernetes secret in the same namespace as the Upstream.
	// Then, refer to the secret in the Upstream configuration. This option is more secure than an inline token,
	// because the API key is encoded and you can restrict access to secrets through RBAC rules.
	// You might use this option in proofs of concept, controlled development and staging environments,
	// or well-controlled prod environments that use secrets.
	SecretRef *core.ResourceRef `protobuf:"bytes,2,opt,name=secret_ref,json=secretRef,proto3,oneof"`
}

type SingleAuthToken_Passthrough_ struct {
	// Passthrough the existing token. This token can either
	// come directly from the client, or be generated by an OIDC flow
	// early in the request lifecycle. This option is useful for
	// backends which have federated identity setup and can re-use
	// the token from the client.
	// Currently, this token must exist in the `Authorization` header.
	Passthrough *SingleAuthToken_Passthrough `protobuf:"bytes,3,opt,name=passthrough,proto3,oneof"`
}

func (*SingleAuthToken_Inline) isSingleAuthToken_AuthTokenSource() {}

func (*SingleAuthToken_SecretRef) isSingleAuthToken_AuthTokenSource() {}

func (*SingleAuthToken_Passthrough_) isSingleAuthToken_AuthTokenSource() {}

// When you deploy the Gloo AI Gateway, you can use the `spec.ai` section of the Upstream resource
// to represent a backend for a logical Large Language Model (LLM) provider.
// This section configures the LLM provider that the AI Gateway routes requests to,
// and how the gateway should authenticate with the provider.
// Note that other Gloo AI Gateway LLM features, such as prompt guards
// and prompt enrichment, are configured at the route level in the
// [`spec.options.ai` section of the RouteOptions resource](#routesettings).
//
// To get started, see [About Gloo AI Gateway](https://docs.solo.io/gateway/latest/ai/overview/).
// For more information about the Upstream resource, see the
// [API reference]({{% versioned_link_path fromRoot="/reference/api/github.com/solo-io/gloo/projects/gloo/api/v1/upstream.proto.sk/" %}}).
//
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Llm:
	//
	//	*UpstreamSpec_Openai
	//	*UpstreamSpec_Mistral_
	//	*UpstreamSpec_Anthropic_
	//	*UpstreamSpec_AzureOpenai
	//	*UpstreamSpec_Multi
	//	*UpstreamSpec_Gemini_
	//	*UpstreamSpec_VertexAi
	//	*UpstreamSpec_Bedrock_
	Llm           isUpstreamSpec_Llm `protobuf_oneof:"llm"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec) Reset() {
	*x = UpstreamSpec{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec) ProtoMessage() {}

func (x *UpstreamSpec) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec.ProtoReflect.Descriptor instead.
func (*UpstreamSpec) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1}
}

func (x *UpstreamSpec) GetLlm() isUpstreamSpec_Llm {
	if x != nil {
		return x.Llm
	}
	return nil
}

func (x *UpstreamSpec) GetOpenai() *UpstreamSpec_OpenAI {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_Openai); ok {
			return x.Openai
		}
	}
	return nil
}

func (x *UpstreamSpec) GetMistral() *UpstreamSpec_Mistral {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_Mistral_); ok {
			return x.Mistral
		}
	}
	return nil
}

func (x *UpstreamSpec) GetAnthropic() *UpstreamSpec_Anthropic {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_Anthropic_); ok {
			return x.Anthropic
		}
	}
	return nil
}

func (x *UpstreamSpec) GetAzureOpenai() *UpstreamSpec_AzureOpenAI {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_AzureOpenai); ok {
			return x.AzureOpenai
		}
	}
	return nil
}

func (x *UpstreamSpec) GetMulti() *UpstreamSpec_MultiPool {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_Multi); ok {
			return x.Multi
		}
	}
	return nil
}

func (x *UpstreamSpec) GetGemini() *UpstreamSpec_Gemini {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_Gemini_); ok {
			return x.Gemini
		}
	}
	return nil
}

func (x *UpstreamSpec) GetVertexAi() *UpstreamSpec_VertexAI {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_VertexAi); ok {
			return x.VertexAi
		}
	}
	return nil
}

func (x *UpstreamSpec) GetBedrock() *UpstreamSpec_Bedrock {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_Bedrock_); ok {
			return x.Bedrock
		}
	}
	return nil
}

type isUpstreamSpec_Llm interface {
	isUpstreamSpec_Llm()
}

type UpstreamSpec_Openai struct {
	// Configure an [OpenAI](https://platform.openai.com/docs/overview) backend.
	Openai *UpstreamSpec_OpenAI `protobuf:"bytes,1,opt,name=openai,proto3,oneof"`
}

type UpstreamSpec_Mistral_ struct {
	// Configure a [Mistral AI](https://docs.mistral.ai/getting-started/quickstart/) backend.
	Mistral *UpstreamSpec_Mistral `protobuf:"bytes,2,opt,name=mistral,proto3,oneof"`
}

type UpstreamSpec_Anthropic_ struct {
	// Configure an [Anthropic](https://docs.anthropic.com/en/release-notes/api) backend.
	Anthropic *UpstreamSpec_Anthropic `protobuf:"bytes,3,opt,name=anthropic,proto3,oneof"`
}

type UpstreamSpec_AzureOpenai struct {
	// Configure an [Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/) backend.
	AzureOpenai *UpstreamSpec_AzureOpenAI `protobuf:"bytes,4,opt,name=azure_openai,json=azureOpenai,proto3,oneof"`
}

type UpstreamSpec_Multi struct {
	// Configure backends for multiple LLM providers in one logical endpoint.
	Multi *UpstreamSpec_MultiPool `protobuf:"bytes,5,opt,name=multi,proto3,oneof"`
}

type UpstreamSpec_Gemini_ struct {
	// Configure a [Gemini](https://ai.google.dev/gemini-api/docs) backend.
	Gemini *UpstreamSpec_Gemini `protobuf:"bytes,6,opt,name=gemini,proto3,oneof"`
}

type UpstreamSpec_VertexAi struct {
	// Configure a [Vertex AI](https://cloud.google.com/vertex-ai/docs) backend.
	VertexAi *UpstreamSpec_VertexAI `protobuf:"bytes,7,opt,name=vertex_ai,json=vertexAi,proto3,oneof"`
}

type UpstreamSpec_Bedrock_ struct {
	// Configure a [Bedrock](https://aws.amazon.com/bedrock/) backend.
	Bedrock *UpstreamSpec_Bedrock `protobuf:"bytes,8,opt,name=bedrock,proto3,oneof"`
}

func (*UpstreamSpec_Openai) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_Mistral_) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_Anthropic_) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_AzureOpenai) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_Multi) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_Gemini_) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_VertexAi) isUpstreamSpec_Llm() {}

func (*UpstreamSpec_Bedrock_) isUpstreamSpec_Llm() {}

// When you deploy the Gloo AI Gateway, you can use the `spec.options.ai` section
// of the RouteOptions resource to configure the behavior of the LLM provider
// on the level of individual routes. These route settings, such as prompt enrichment,
// retrieval augmented generation (RAG), and semantic caching, are applicable only
// for routes that send requests to an LLM provider backend.
//
// For more information about the RouteOptions resource, see the
// [API reference]({{% versioned_link_path fromRoot="/reference/api/github.com/solo-io/gloo/projects/gloo/api/v1/route_options.proto.sk/" %}}).
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type RouteSettings struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Enrich requests sent to the LLM provider by appending and prepending system prompts.
	// This can be configured only for LLM providers that use the `CHAT` API route type.
	PromptEnrichment *AIPromptEnrichment `protobuf:"bytes,1,opt,name=prompt_enrichment,json=promptEnrichment,proto3" json:"prompt_enrichment,omitempty"`
	// Set up prompt guards to block unwanted requests to the LLM provider and mask sensitive data.
	// Prompt guards can be used to reject requests based on the content of the prompt, as well as
	// mask responses based on the content of the response.
	PromptGuard *AIPromptGuard `protobuf:"bytes,2,opt,name=prompt_guard,json=promptGuard,proto3" json:"prompt_guard,omitempty"`
	// [Retrieval augmented generation (RAG)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)
	// is a technique of providing relevant context by retrieving relevant data from one or more
	// context datasets and augmenting the prompt with the retrieved information.
	// This can be used to improve the quality of the generated text.
	Rag *RAG `protobuf:"bytes,3,opt,name=rag,proto3" json:"rag,omitempty"`
	// Cache previous model responses to provide faster responses to similar requests in the future.
	// Results might vary depending on the embedding mechanism used, as well
	// as the similarity threshold set.
	SemanticCache *SemanticCache `protobuf:"bytes,4,opt,name=semantic_cache,json=semanticCache,proto3" json:"semantic_cache,omitempty"`
	// Provide defaults to merge with user input fields.
	// Defaults do _not_ override the user input fields, unless you explicitly set `override` to `true`.
	Defaults []*FieldDefault `protobuf:"bytes,5,rep,name=defaults,proto3" json:"defaults,omitempty"`
	// The type of route to the LLM provider API. Currently, `CHAT` and `CHAT_STREAMING` are supported.
	RouteType     RouteSettings_RouteType `protobuf:"varint,6,opt,name=route_type,json=routeType,proto3,enum=ai.options.gloo.solo.io.RouteSettings_RouteType" json:"route_type,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RouteSettings) Reset() {
	*x = RouteSettings{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RouteSettings) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RouteSettings) ProtoMessage() {}

func (x *RouteSettings) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RouteSettings.ProtoReflect.Descriptor instead.
func (*RouteSettings) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{2}
}

func (x *RouteSettings) GetPromptEnrichment() *AIPromptEnrichment {
	if x != nil {
		return x.PromptEnrichment
	}
	return nil
}

func (x *RouteSettings) GetPromptGuard() *AIPromptGuard {
	if x != nil {
		return x.PromptGuard
	}
	return nil
}

func (x *RouteSettings) GetRag() *RAG {
	if x != nil {
		return x.Rag
	}
	return nil
}

func (x *RouteSettings) GetSemanticCache() *SemanticCache {
	if x != nil {
		return x.SemanticCache
	}
	return nil
}

func (x *RouteSettings) GetDefaults() []*FieldDefault {
	if x != nil {
		return x.Defaults
	}
	return nil
}

func (x *RouteSettings) GetRouteType() RouteSettings_RouteType {
	if x != nil {
		return x.RouteType
	}
	return RouteSettings_CHAT
}

// Provide defaults to merge with user input fields.
// Defaults do _not_ override the user input fields, unless you explicitly set `override` to `true`.
//
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
//
// Example overriding the system field for Anthropic:
// ```yaml
// # Anthropic doesn't support a system chat type
// defaults:
//   - field: "system"
//     value: "answer all questions in french"
//
// ```
//
// Example setting the temperature and overriding `max_tokens`:
// ```yaml
// defaults:
//   - field: "temperature"
//     value: 0.5
//   - field: "max_tokens"
//     value: 100
//
// ```
type FieldDefault struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the field.
	Field string `protobuf:"bytes,1,opt,name=field,proto3" json:"field,omitempty"`
	// The field default value, which can be any JSON Data Type.
	Value *structpb.Value `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
	// Whether to override the field's value if it already exists.
	// Defaults to false.
	Override      bool `protobuf:"varint,3,opt,name=override,proto3" json:"override,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FieldDefault) Reset() {
	*x = FieldDefault{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FieldDefault) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FieldDefault) ProtoMessage() {}

func (x *FieldDefault) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FieldDefault.ProtoReflect.Descriptor instead.
func (*FieldDefault) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{3}
}

func (x *FieldDefault) GetField() string {
	if x != nil {
		return x.Field
	}
	return ""
}

func (x *FieldDefault) GetValue() *structpb.Value {
	if x != nil {
		return x.Value
	}
	return nil
}

func (x *FieldDefault) GetOverride() bool {
	if x != nil {
		return x.Override
	}
	return false
}

// Configuration settings for a Postgres datastore.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type Postgres struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Connection string to the Postgres database. For example, to use a vector database
	// deployed to your cluster, your connection string might look similar to
	// `postgresql+psycopg://gloo:gloo@vector-db.default.svc.cluster.local:5432/gloo`.
	ConnectionString string `protobuf:"bytes,1,opt,name=connection_string,json=connectionString,proto3" json:"connection_string,omitempty"`
	// Name of the collection table to use.
	CollectionName string `protobuf:"bytes,2,opt,name=collection_name,json=collectionName,proto3" json:"collection_name,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *Postgres) Reset() {
	*x = Postgres{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Postgres) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Postgres) ProtoMessage() {}

func (x *Postgres) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Postgres.ProtoReflect.Descriptor instead.
func (*Postgres) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{4}
}

func (x *Postgres) GetConnectionString() string {
	if x != nil {
		return x.ConnectionString
	}
	return ""
}

func (x *Postgres) GetCollectionName() string {
	if x != nil {
		return x.CollectionName
	}
	return ""
}

// Configuration of the API used to generate the embedding.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type Embedding struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Configuration for the backend LLM provider authentication token.
	//
	// Types that are valid to be assigned to Embedding:
	//
	//	*Embedding_Openai
	//	*Embedding_AzureOpenai
	Embedding     isEmbedding_Embedding `protobuf_oneof:"embedding"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Embedding) Reset() {
	*x = Embedding{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Embedding) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Embedding) ProtoMessage() {}

func (x *Embedding) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Embedding.ProtoReflect.Descriptor instead.
func (*Embedding) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{5}
}

func (x *Embedding) GetEmbedding() isEmbedding_Embedding {
	if x != nil {
		return x.Embedding
	}
	return nil
}

func (x *Embedding) GetOpenai() *Embedding_OpenAI {
	if x != nil {
		if x, ok := x.Embedding.(*Embedding_Openai); ok {
			return x.Openai
		}
	}
	return nil
}

func (x *Embedding) GetAzureOpenai() *Embedding_AzureOpenAI {
	if x != nil {
		if x, ok := x.Embedding.(*Embedding_AzureOpenai); ok {
			return x.AzureOpenai
		}
	}
	return nil
}

type isEmbedding_Embedding interface {
	isEmbedding_Embedding()
}

type Embedding_Openai struct {
	// Embedding settings for the OpenAI provider.
	Openai *Embedding_OpenAI `protobuf:"bytes,1,opt,name=openai,proto3,oneof"`
}

type Embedding_AzureOpenai struct {
	// Embedding settings for the Azure OpenAI provider.
	AzureOpenai *Embedding_AzureOpenAI `protobuf:"bytes,2,opt,name=azure_openai,json=azureOpenai,proto3,oneof"`
}

func (*Embedding_Openai) isEmbedding_Embedding() {}

func (*Embedding_AzureOpenai) isEmbedding_Embedding() {}

// Cache previous model responses to provide faster responses to similar requests in the future.
// Results might vary depending on the embedding mechanism used, as well
// as the similarity threshold set. Semantic caching reduces the number of requests
// to the LLM provider, improves the response time, and reduces costs.
//
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
//
// Example configuring a route to use a `redis` datastore and OpenAI for RAG:
// ```yaml
// semanticCache:
//
//	datastore:
//	  redis:
//	    connectionString: redis://172.17.0.1:6379
//	embedding:
//	  openai:
//	    authToken:
//	      secretRef:
//	        name: openai-secret
//	        namespace: gloo-system
//
// ```
type SemanticCache struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Data store from which to cache the request and response pairs.
	Datastore *SemanticCache_DataStore `protobuf:"bytes,1,opt,name=datastore,proto3" json:"datastore,omitempty"`
	// Model to use to retrieve the embedding mechanism.
	Embedding *Embedding `protobuf:"bytes,2,opt,name=embedding,proto3" json:"embedding,omitempty"`
	// Time before data in the cache is considered expired.
	Ttl uint32 `protobuf:"varint,3,opt,name=ttl,proto3" json:"ttl,omitempty"`
	// The caching mode to use for the request and response lifecycle. Supported values include `READ_WRITE` or `READ_ONLY`.
	Mode SemanticCache_Mode `protobuf:"varint,4,opt,name=mode,proto3,enum=ai.options.gloo.solo.io.SemanticCache_Mode" json:"mode,omitempty"`
	// Distance score threshold value between 0.0 and 1.0 that determines how similar
	// two queries must be in order to return a cached result.
	// The lower the number, the more similar the queries must be for a cache hit.
	//
	// +kubebuilder:validation:Minimum=0
	// +kubebuilder:validation:Maximum=1
	DistanceThreshold float32 `protobuf:"fixed32,5,opt,name=distance_threshold,json=distanceThreshold,proto3" json:"distance_threshold,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *SemanticCache) Reset() {
	*x = SemanticCache{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SemanticCache) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SemanticCache) ProtoMessage() {}

func (x *SemanticCache) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SemanticCache.ProtoReflect.Descriptor instead.
func (*SemanticCache) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{6}
}

func (x *SemanticCache) GetDatastore() *SemanticCache_DataStore {
	if x != nil {
		return x.Datastore
	}
	return nil
}

func (x *SemanticCache) GetEmbedding() *Embedding {
	if x != nil {
		return x.Embedding
	}
	return nil
}

func (x *SemanticCache) GetTtl() uint32 {
	if x != nil {
		return x.Ttl
	}
	return 0
}

func (x *SemanticCache) GetMode() SemanticCache_Mode {
	if x != nil {
		return x.Mode
	}
	return SemanticCache_READ_WRITE
}

func (x *SemanticCache) GetDistanceThreshold() float32 {
	if x != nil {
		return x.DistanceThreshold
	}
	return 0
}

// [Retrieval augmented generation (RAG)](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)
// is a technique of providing relevant context by retrieving relevant data from one or more
// context datasets and augmenting the prompt with the retrieved information.
// This can be used to improve the quality of the generated text.
//
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
//
// {{% notice note %}}
// The same embedding mechanism that was used for the initial
// creation of the context datasets must be used for the prompt.
// {{% /notice %}}
//
// Example configuring a route to use a `postgres` datastore and OpenAI for RAG:
// ```yaml
// rag:
//
//	datastore:
//	  postgres:
//	    connectionString: postgresql+psycopg://gloo:gloo@172.17.0.1:6024/gloo
//	    collectionName: default
//	embedding:
//	  openai:
//	    authToken:
//	      secretRef:
//	        name: openai-secret
//	        namespace: gloo-system
//
// ```
//
// {{% notice tip %}}
// For an extended example that includes deploying a vector database with a context dataset,
// check out the [Retrieval augmented generation (RAG) tutorial](https://docs.solo.io/gateway/main/ai/tutorials/rag/).
// {{% /notice %}}
type RAG struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Data store from which to fetch the context embeddings.
	Datastore *RAG_DataStore `protobuf:"bytes,1,opt,name=datastore,proto3" json:"datastore,omitempty"`
	// Model to use to retrieve the context embeddings.
	Embedding *Embedding `protobuf:"bytes,2,opt,name=embedding,proto3" json:"embedding,omitempty"`
	// Template to use to embed the returned context.
	PromptTemplate string `protobuf:"bytes,3,opt,name=prompt_template,json=promptTemplate,proto3" json:"prompt_template,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *RAG) Reset() {
	*x = RAG{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RAG) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RAG) ProtoMessage() {}

func (x *RAG) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RAG.ProtoReflect.Descriptor instead.
func (*RAG) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{7}
}

func (x *RAG) GetDatastore() *RAG_DataStore {
	if x != nil {
		return x.Datastore
	}
	return nil
}

func (x *RAG) GetEmbedding() *Embedding {
	if x != nil {
		return x.Embedding
	}
	return nil
}

func (x *RAG) GetPromptTemplate() string {
	if x != nil {
		return x.PromptTemplate
	}
	return ""
}

// Enrich requests sent to the LLM provider by appending and prepending system prompts.
// This can be configured only for LLM providers that use the CHAT API type.
//
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
// Prompt enrichment allows you to add additional context to the prompt before sending it to the model.
// Unlike RAG or other dynamic context methods, prompt enrichment is static and is applied to every request.
//
// **Note**: Some providers, including Anthropic, do not support SYSTEM role messages, and instead have a dedicated
// system field in the input JSON. In this case, use the [`defaults` setting](#fielddefault) to set the system field.
//
// The following example prepends a system prompt of `Answer all questions in French.`
// and appends `Describe the painting as if you were a famous art critic from the 17th century.`
// to each request that is sent to the `openai` HTTPRoute.
// ```yaml
// apiVersion: gateway.solo.io/v1
// kind: RouteOption
// metadata:
//
//	name: openai-opt
//	namespace: gloo-system
//
// spec:
//
//	targetRefs:
//	- group: gateway.networking.k8s.io
//	  kind: HTTPRoute
//	  name: openai
//	options:
//	  ai:
//	    promptEnrichment:
//	      prepend:
//	      - role: SYSTEM
//	        content: "Answer all questions in French."
//	      append:
//	      - role: USER
//	        content: "Describe the painting as if you were a famous art critic from the 17th century."
//
// ```
type AIPromptEnrichment struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A list of messages to be prepended to the prompt sent by the client.
	Prepend []*AIPromptEnrichment_Message `protobuf:"bytes,2,rep,name=prepend,proto3" json:"prepend,omitempty"`
	// A list of messages to be appended to the prompt sent by the client.
	Append        []*AIPromptEnrichment_Message `protobuf:"bytes,3,rep,name=append,proto3" json:"append,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptEnrichment) Reset() {
	*x = AIPromptEnrichment{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptEnrichment) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptEnrichment) ProtoMessage() {}

func (x *AIPromptEnrichment) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptEnrichment.ProtoReflect.Descriptor instead.
func (*AIPromptEnrichment) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{8}
}

func (x *AIPromptEnrichment) GetPrepend() []*AIPromptEnrichment_Message {
	if x != nil {
		return x.Prepend
	}
	return nil
}

func (x *AIPromptEnrichment) GetAppend() []*AIPromptEnrichment_Message {
	if x != nil {
		return x.Append
	}
	return nil
}

// Set up prompt guards to block unwanted requests to the LLM provider and mask sensitive data.
// Prompt guards can be used to reject requests based on the content of the prompt, as well as
// mask responses based on the content of the response.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
//
// This example rejects any request prompts that contain
// the string "credit card", and masks any credit card numbers in the response.
// ```yaml
// promptGuard:
//
//	request:
//	  customResponse:
//	    message: "Rejected due to inappropriate content"
//	  regex:
//	    action: REJECT
//	    matches:
//	    - pattern: "credit card"
//	      name: "CC"
//	response:
//	  regex:
//	    builtins:
//	    - CREDIT_CARD
//	    action: MASK
//
// ```
type AIPromptGuard struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Prompt guards to apply to requests sent by the client.
	Request *AIPromptGuard_Request `protobuf:"bytes,1,opt,name=request,proto3" json:"request,omitempty"`
	// Prompt guards to apply to responses returned by the LLM provider.
	Response      *AIPromptGuard_Response `protobuf:"bytes,2,opt,name=response,proto3" json:"response,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard) Reset() {
	*x = AIPromptGuard{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard) ProtoMessage() {}

func (x *AIPromptGuard) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard.ProtoReflect.Descriptor instead.
func (*AIPromptGuard) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9}
}

func (x *AIPromptGuard) GetRequest() *AIPromptGuard_Request {
	if x != nil {
		return x.Request
	}
	return nil
}

func (x *AIPromptGuard) GetResponse() *AIPromptGuard_Response {
	if x != nil {
		return x.Response
	}
	return nil
}

// Configuration for passthrough of the existing token.
// Currently, specifying an empty object (`passthrough: {}`)
// indicates that passthrough will be used for auth.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type SingleAuthToken_Passthrough struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SingleAuthToken_Passthrough) Reset() {
	*x = SingleAuthToken_Passthrough{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SingleAuthToken_Passthrough) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SingleAuthToken_Passthrough) ProtoMessage() {}

func (x *SingleAuthToken_Passthrough) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SingleAuthToken_Passthrough.ProtoReflect.Descriptor instead.
func (*SingleAuthToken_Passthrough) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{0, 0}
}

// Send requests to a custom host and port, such as to proxy the request,
// or to use a different backend that is API-compliant with the upstream version.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_CustomHost struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Custom host or IP address to send the traffic requests to.
	Host string `protobuf:"bytes,1,opt,name=host,proto3" json:"host,omitempty"`
	// Custom port to send the traffic requests to.
	Port uint32 `protobuf:"varint,2,opt,name=port,proto3" json:"port,omitempty"`
	// Optional: hostname used to set the SNI (if is secure connection) and the host request header.
	// If hostname is not set, host will be used instead
	Hostname      *wrapperspb.StringValue `protobuf:"bytes,3,opt,name=hostname,proto3" json:"hostname,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_CustomHost) Reset() {
	*x = UpstreamSpec_CustomHost{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_CustomHost) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_CustomHost) ProtoMessage() {}

func (x *UpstreamSpec_CustomHost) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_CustomHost.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_CustomHost) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 0}
}

func (x *UpstreamSpec_CustomHost) GetHost() string {
	if x != nil {
		return x.Host
	}
	return ""
}

func (x *UpstreamSpec_CustomHost) GetPort() uint32 {
	if x != nil {
		return x.Port
	}
	return 0
}

func (x *UpstreamSpec_CustomHost) GetHostname() *wrapperspb.StringValue {
	if x != nil {
		return x.Hostname
	}
	return nil
}

// Settings for the [OpenAI](https://platform.openai.com/docs/overview) LLM provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_OpenAI struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization token that the AI gateway uses to access the OpenAI API.
	// This token is automatically sent in the `Authorization` header of the
	// request and prefixed with `Bearer`.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3" json:"auth_token,omitempty"`
	// Optional: Send requests to a custom host and port, such as to proxy the request,
	// or to use a different backend that is API-compliant with the upstream version.
	CustomHost *UpstreamSpec_CustomHost `protobuf:"bytes,2,opt,name=custom_host,json=customHost,proto3" json:"custom_host,omitempty"`
	// Optional: Override the model name, such as `gpt-4o-mini`.
	// If unset, the model name is taken from the request.
	// This setting can be useful when setting up model failover within the same LLM provider.
	Model         string `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_OpenAI) Reset() {
	*x = UpstreamSpec_OpenAI{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_OpenAI) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_OpenAI) ProtoMessage() {}

func (x *UpstreamSpec_OpenAI) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_OpenAI.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_OpenAI) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 1}
}

func (x *UpstreamSpec_OpenAI) GetAuthToken() *SingleAuthToken {
	if x != nil {
		return x.AuthToken
	}
	return nil
}

func (x *UpstreamSpec_OpenAI) GetCustomHost() *UpstreamSpec_CustomHost {
	if x != nil {
		return x.CustomHost
	}
	return nil
}

func (x *UpstreamSpec_OpenAI) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

// Settings for the [Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/) LLM provider.
// To find the values for the endpoint, deployment name, and API version, you can check the fields of an API request, such as
// `https://{endpoint}/openai/deployments/{deployment_name}/chat/completions?api-version={api_version}`.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_AzureOpenAI struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization token that the AI gateway uses to access the Azure OpenAI API.
	// This token is automatically sent in the `api-key` header of the request.
	//
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*UpstreamSpec_AzureOpenAI_AuthToken
	AuthTokenSource isUpstreamSpec_AzureOpenAI_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	// The endpoint for the Azure OpenAI API to use, such as `my-endpoint.openai.azure.com`.
	// If the scheme is included, it is stripped.
	Endpoint string `protobuf:"bytes,2,opt,name=endpoint,proto3" json:"endpoint,omitempty"`
	// The name of the Azure OpenAI model deployment to use.
	// For more information, see the [Azure OpenAI model docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models).
	DeploymentName string `protobuf:"bytes,3,opt,name=deployment_name,json=deploymentName,proto3" json:"deployment_name,omitempty"`
	// The version of the Azure OpenAI API to use.
	// For more information, see the [Azure OpenAI API version reference](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs).
	ApiVersion    string `protobuf:"bytes,4,opt,name=api_version,json=apiVersion,proto3" json:"api_version,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_AzureOpenAI) Reset() {
	*x = UpstreamSpec_AzureOpenAI{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_AzureOpenAI) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_AzureOpenAI) ProtoMessage() {}

func (x *UpstreamSpec_AzureOpenAI) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_AzureOpenAI.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_AzureOpenAI) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 2}
}

func (x *UpstreamSpec_AzureOpenAI) GetAuthTokenSource() isUpstreamSpec_AzureOpenAI_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *UpstreamSpec_AzureOpenAI) GetAuthToken() *SingleAuthToken {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*UpstreamSpec_AzureOpenAI_AuthToken); ok {
			return x.AuthToken
		}
	}
	return nil
}

func (x *UpstreamSpec_AzureOpenAI) GetEndpoint() string {
	if x != nil {
		return x.Endpoint
	}
	return ""
}

func (x *UpstreamSpec_AzureOpenAI) GetDeploymentName() string {
	if x != nil {
		return x.DeploymentName
	}
	return ""
}

func (x *UpstreamSpec_AzureOpenAI) GetApiVersion() string {
	if x != nil {
		return x.ApiVersion
	}
	return ""
}

type isUpstreamSpec_AzureOpenAI_AuthTokenSource interface {
	isUpstreamSpec_AzureOpenAI_AuthTokenSource()
}

type UpstreamSpec_AzureOpenAI_AuthToken struct {
	// The authorization token that the AI gateway uses to access the Azure OpenAI API.
	// This token is automatically sent in the `api-key` header of the request.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3,oneof"` // use AD or other workload identity mechanism
}

func (*UpstreamSpec_AzureOpenAI_AuthToken) isUpstreamSpec_AzureOpenAI_AuthTokenSource() {}

// Settings for the [Gemini](https://ai.google.dev/gemini-api/docs) LLM provider.
// To find the values for the model and API version, you can check the fields of an API request, such as
// `https://generativelanguage.googleapis.com/{version}/models/{model}:generateContent?key={api_key}`.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_Gemini struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization token that the AI gateway uses to access the Gemini API.
	// This token is automatically sent in the `x-goog-api-key` header of the request.
	//
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*UpstreamSpec_Gemini_AuthToken
	AuthTokenSource isUpstreamSpec_Gemini_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	// The Gemini model to use.
	// For more information, see the [Gemini models docs](https://ai.google.dev/gemini-api/docs/models/gemini).
	Model string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	// The version of the Gemini API to use.
	// For more information, see the [Gemini API version docs](https://ai.google.dev/gemini-api/docs/api-versions).
	ApiVersion    string `protobuf:"bytes,3,opt,name=api_version,json=apiVersion,proto3" json:"api_version,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_Gemini) Reset() {
	*x = UpstreamSpec_Gemini{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_Gemini) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_Gemini) ProtoMessage() {}

func (x *UpstreamSpec_Gemini) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_Gemini.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_Gemini) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 3}
}

func (x *UpstreamSpec_Gemini) GetAuthTokenSource() isUpstreamSpec_Gemini_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *UpstreamSpec_Gemini) GetAuthToken() *SingleAuthToken {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*UpstreamSpec_Gemini_AuthToken); ok {
			return x.AuthToken
		}
	}
	return nil
}

func (x *UpstreamSpec_Gemini) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *UpstreamSpec_Gemini) GetApiVersion() string {
	if x != nil {
		return x.ApiVersion
	}
	return ""
}

type isUpstreamSpec_Gemini_AuthTokenSource interface {
	isUpstreamSpec_Gemini_AuthTokenSource()
}

type UpstreamSpec_Gemini_AuthToken struct {
	// The authorization token that the AI gateway uses to access the Gemini API.
	// This token is automatically sent in the `x-goog-api-key` header of the request.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3,oneof"` // TODO: use oauth
}

func (*UpstreamSpec_Gemini_AuthToken) isUpstreamSpec_Gemini_AuthTokenSource() {}

// Settings for the [Vertex AI](https://cloud.google.com/vertex-ai/docs) LLM provider.
// To find the values for the project ID, project location, and publisher, you can check the fields of an API request, such as
// `https://{LOCATION}-aiplatform.googleapis.com/{VERSION}/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/{PROVIDER}/<model-path>`.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_VertexAI struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization token that the AI gateway uses to access the Vertex AI API.
	// This token is automatically sent in the `key` header of the request.
	//
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*UpstreamSpec_VertexAI_AuthToken
	AuthTokenSource isUpstreamSpec_VertexAI_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	// The Vertex AI model to use.
	// For more information, see the [Vertex AI model docs](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models).
	Model string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	// The version of the Vertex AI API to use.
	// For more information, see the [Vertex AI API reference](https://cloud.google.com/vertex-ai/docs/reference#versions).
	ApiVersion string `protobuf:"bytes,3,opt,name=api_version,json=apiVersion,proto3" json:"api_version,omitempty"`
	// The ID of the Google Cloud Project that you use for the Vertex AI.
	ProjectId string `protobuf:"bytes,4,opt,name=project_id,json=projectId,proto3" json:"project_id,omitempty"`
	// The location of the Google Cloud Project that you use for the Vertex AI.
	Location string `protobuf:"bytes,5,opt,name=location,proto3" json:"location,omitempty"`
	// Optional: The model path to route to. Defaults to the Gemini model path, `generateContent`.
	ModelPath string `protobuf:"bytes,6,opt,name=model_path,json=modelPath,proto3" json:"model_path,omitempty"`
	// The type of publisher model to use. Currently, only Google is supported.
	Publisher UpstreamSpec_VertexAI_Publisher `protobuf:"varint,7,opt,name=publisher,proto3,enum=ai.options.gloo.solo.io.UpstreamSpec_VertexAI_Publisher" json:"publisher,omitempty"`
	// Optional: Specify the API json schema the model uses, default to GEMINI if not set
	JsonSchema    ApiJsonSchema `protobuf:"varint,8,opt,name=json_schema,json=jsonSchema,proto3,enum=ai.options.gloo.solo.io.ApiJsonSchema" json:"json_schema,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_VertexAI) Reset() {
	*x = UpstreamSpec_VertexAI{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_VertexAI) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_VertexAI) ProtoMessage() {}

func (x *UpstreamSpec_VertexAI) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_VertexAI.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_VertexAI) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 4}
}

func (x *UpstreamSpec_VertexAI) GetAuthTokenSource() isUpstreamSpec_VertexAI_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *UpstreamSpec_VertexAI) GetAuthToken() *SingleAuthToken {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*UpstreamSpec_VertexAI_AuthToken); ok {
			return x.AuthToken
		}
	}
	return nil
}

func (x *UpstreamSpec_VertexAI) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *UpstreamSpec_VertexAI) GetApiVersion() string {
	if x != nil {
		return x.ApiVersion
	}
	return ""
}

func (x *UpstreamSpec_VertexAI) GetProjectId() string {
	if x != nil {
		return x.ProjectId
	}
	return ""
}

func (x *UpstreamSpec_VertexAI) GetLocation() string {
	if x != nil {
		return x.Location
	}
	return ""
}

func (x *UpstreamSpec_VertexAI) GetModelPath() string {
	if x != nil {
		return x.ModelPath
	}
	return ""
}

func (x *UpstreamSpec_VertexAI) GetPublisher() UpstreamSpec_VertexAI_Publisher {
	if x != nil {
		return x.Publisher
	}
	return UpstreamSpec_VertexAI_GOOGLE
}

func (x *UpstreamSpec_VertexAI) GetJsonSchema() ApiJsonSchema {
	if x != nil {
		return x.JsonSchema
	}
	return ApiJsonSchema_NOT_SET
}

type isUpstreamSpec_VertexAI_AuthTokenSource interface {
	isUpstreamSpec_VertexAI_AuthTokenSource()
}

type UpstreamSpec_VertexAI_AuthToken struct {
	// The authorization token that the AI gateway uses to access the Vertex AI API.
	// This token is automatically sent in the `key` header of the request.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3,oneof"` // TODO: use oauth
}

func (*UpstreamSpec_VertexAI_AuthToken) isUpstreamSpec_VertexAI_AuthTokenSource() {}

// Settings for the [Mistral AI](https://docs.mistral.ai/getting-started/quickstart/) LLM provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_Mistral struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization token that the AI gateway uses to access the OpenAI API.
	// This token is automatically sent in the `Authorization` header of the
	// request and prefixed with `Bearer`.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3" json:"auth_token,omitempty"`
	// Optional: Send requests to a custom host and port, such as to proxy the request,
	// or to use a different backend that is API-compliant with the upstream version.
	CustomHost *UpstreamSpec_CustomHost `protobuf:"bytes,2,opt,name=custom_host,json=customHost,proto3" json:"custom_host,omitempty"`
	// Optional: Override the model name.
	// If unset, the model name is taken from the request.
	// This setting can be useful when testing model failover scenarios.
	Model         string `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_Mistral) Reset() {
	*x = UpstreamSpec_Mistral{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_Mistral) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_Mistral) ProtoMessage() {}

func (x *UpstreamSpec_Mistral) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_Mistral.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_Mistral) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 5}
}

func (x *UpstreamSpec_Mistral) GetAuthToken() *SingleAuthToken {
	if x != nil {
		return x.AuthToken
	}
	return nil
}

func (x *UpstreamSpec_Mistral) GetCustomHost() *UpstreamSpec_CustomHost {
	if x != nil {
		return x.CustomHost
	}
	return nil
}

func (x *UpstreamSpec_Mistral) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

// Settings for the [Anthropic](https://docs.anthropic.com/en/release-notes/api) LLM provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_Anthropic struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization token that the AI gateway uses to access the Anthropic API.
	// This token is automatically sent in the `x-api-key` header of the request.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3" json:"auth_token,omitempty"`
	// Optional: Send requests to a custom host and port, such as to proxy the request,
	// or to use a different backend that is API-compliant with the upstream version.
	CustomHost *UpstreamSpec_CustomHost `protobuf:"bytes,2,opt,name=custom_host,json=customHost,proto3" json:"custom_host,omitempty"`
	// Optional: The version string used to override the `anthropic-version` header to pass to the Anthropic API.
	// Note: This does not control the api version (eg `/v1`) in the url.
	// For more information, see the [Anthropic API versioning docs](https://docs.anthropic.com/en/api/versioning).
	Version string `protobuf:"bytes,3,opt,name=version,proto3" json:"version,omitempty"`
	// Optional: Override the model name.
	// If unset, the model name is taken from the request.
	// This setting can be useful when testing model failover scenarios.
	Model         string `protobuf:"bytes,4,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_Anthropic) Reset() {
	*x = UpstreamSpec_Anthropic{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_Anthropic) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_Anthropic) ProtoMessage() {}

func (x *UpstreamSpec_Anthropic) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_Anthropic.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_Anthropic) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 6}
}

func (x *UpstreamSpec_Anthropic) GetAuthToken() *SingleAuthToken {
	if x != nil {
		return x.AuthToken
	}
	return nil
}

func (x *UpstreamSpec_Anthropic) GetCustomHost() *UpstreamSpec_CustomHost {
	if x != nil {
		return x.CustomHost
	}
	return nil
}

func (x *UpstreamSpec_Anthropic) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *UpstreamSpec_Anthropic) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

// Settings for the Bedrock LLM provider
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_Bedrock struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The authorization config used to access authenticated AWS Bedrock services.
	CredentialProvider *UpstreamSpec_AwsCredentialProvider `protobuf:"bytes,1,opt,name=credential_provider,json=credentialProvider,proto3" json:"credential_provider,omitempty"`
	// Optional: Send requests to a custom host and port, such as to proxy the request,
	// or to use a different backend that is API-compliant with the upstream version.
	// Note: For AWS Bedrock, if custom_host is set, host_rewrite will be used to override the Host header before signing the request
	CustomHost *UpstreamSpec_CustomHost `protobuf:"bytes,2,opt,name=custom_host,json=customHost,proto3" json:"custom_host,omitempty"`
	// Optional: Sets the model-id name.
	// If unset, the model name is taken from the request.
	Model string `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	// Required: region string.
	//
	// The region is a string for the standard AWS region for the service that hosts the HTTP endpoint. The `AWS_SIGV4` signing algorithm is currently used by default.
	// For more regions, see the AWS docs <https://docs.aws.amazon.com/general/latest/gr/rande.html>
	//
	// Example: us-west-2
	//
	// NOTE: Multiple regions are not currently supported.
	Region        string `protobuf:"bytes,4,opt,name=region,proto3" json:"region,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_Bedrock) Reset() {
	*x = UpstreamSpec_Bedrock{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_Bedrock) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_Bedrock) ProtoMessage() {}

func (x *UpstreamSpec_Bedrock) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_Bedrock.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_Bedrock) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 7}
}

func (x *UpstreamSpec_Bedrock) GetCredentialProvider() *UpstreamSpec_AwsCredentialProvider {
	if x != nil {
		return x.CredentialProvider
	}
	return nil
}

func (x *UpstreamSpec_Bedrock) GetCustomHost() *UpstreamSpec_CustomHost {
	if x != nil {
		return x.CustomHost
	}
	return nil
}

func (x *UpstreamSpec_Bedrock) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *UpstreamSpec_Bedrock) GetRegion() string {
	if x != nil {
		return x.Region
	}
	return ""
}

// AwsCredentialProvider provider for signing the request.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_AwsCredentialProvider struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*UpstreamSpec_AwsCredentialProvider_SecretRef
	//	*UpstreamSpec_AwsCredentialProvider_Inline
	AuthTokenSource isUpstreamSpec_AwsCredentialProvider_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *UpstreamSpec_AwsCredentialProvider) Reset() {
	*x = UpstreamSpec_AwsCredentialProvider{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_AwsCredentialProvider) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_AwsCredentialProvider) ProtoMessage() {}

func (x *UpstreamSpec_AwsCredentialProvider) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_AwsCredentialProvider.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_AwsCredentialProvider) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 8}
}

func (x *UpstreamSpec_AwsCredentialProvider) GetAuthTokenSource() isUpstreamSpec_AwsCredentialProvider_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *UpstreamSpec_AwsCredentialProvider) GetSecretRef() *core.ResourceRef {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*UpstreamSpec_AwsCredentialProvider_SecretRef); ok {
			return x.SecretRef
		}
	}
	return nil
}

func (x *UpstreamSpec_AwsCredentialProvider) GetInline() *UpstreamSpec_AWSInline {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*UpstreamSpec_AwsCredentialProvider_Inline); ok {
			return x.Inline
		}
	}
	return nil
}

type isUpstreamSpec_AwsCredentialProvider_AuthTokenSource interface {
	isUpstreamSpec_AwsCredentialProvider_AuthTokenSource()
}

type UpstreamSpec_AwsCredentialProvider_SecretRef struct {
	// Store the “AWS_ACCESS_KEY_ID“, “AWS_SECRET_ACCESS_KEY“, and the optional “AWS_SESSION_TOKEN“ in a Kubernetes secret in
	// the same namespace as the Upstream. Then, refer to the secret in the Upstream configuration.
	SecretRef *core.ResourceRef `protobuf:"bytes,1,opt,name=secret_ref,json=secretRef,proto3,oneof"`
}

type UpstreamSpec_AwsCredentialProvider_Inline struct {
	// Uses inlined AWS credentials for“AWS_ACCESS_KEY_ID“, “AWS_SECRET_ACCESS_KEY“, and the optional “AWS_SESSION_TOKEN“.
	Inline *UpstreamSpec_AWSInline `protobuf:"bytes,2,opt,name=inline,proto3,oneof"`
}

func (*UpstreamSpec_AwsCredentialProvider_SecretRef) isUpstreamSpec_AwsCredentialProvider_AuthTokenSource() {
}

func (*UpstreamSpec_AwsCredentialProvider_Inline) isUpstreamSpec_AwsCredentialProvider_AuthTokenSource() {
}

// Configuration to use an inline AWS credential. This is an equivalent to setting the well-known
// environment variables “AWS_ACCESS_KEY_ID“, “AWS_SECRET_ACCESS_KEY“, and the optional “AWS_SESSION_TOKEN“.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_AWSInline struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The AWS access key ID, which identifies the user and account.
	AccessKeyId string `protobuf:"bytes,1,opt,name=access_key_id,json=accessKeyId,proto3" json:"access_key_id,omitempty"`
	// The AWS secret access key, which is used to sign the request.
	SecretAccessKey string `protobuf:"bytes,2,opt,name=secret_access_key,json=secretAccessKey,proto3" json:"secret_access_key,omitempty"`
	// The AWS session token. This value is required only when using temporary credentials, such as from STS or an assumed role.
	SessionToken  string `protobuf:"bytes,3,opt,name=session_token,json=sessionToken,proto3" json:"session_token,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_AWSInline) Reset() {
	*x = UpstreamSpec_AWSInline{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_AWSInline) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_AWSInline) ProtoMessage() {}

func (x *UpstreamSpec_AWSInline) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_AWSInline.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_AWSInline) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 9}
}

func (x *UpstreamSpec_AWSInline) GetAccessKeyId() string {
	if x != nil {
		return x.AccessKeyId
	}
	return ""
}

func (x *UpstreamSpec_AWSInline) GetSecretAccessKey() string {
	if x != nil {
		return x.SecretAccessKey
	}
	return ""
}

func (x *UpstreamSpec_AWSInline) GetSessionToken() string {
	if x != nil {
		return x.SessionToken
	}
	return ""
}

// Configure backends for multiple hosts or models from the same provider in one Upstream resource.
// This method can be useful for creating one logical endpoint that is backed
// by multiple hosts or models.
//
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
//
// In the `priorities` section, the order of `pool` entries defines the priority of the backend endpoints.
// The `pool` entries can either define a list of backends or a single backend.
// Note: Only two levels of nesting are permitted. Any nested entries after the second level are ignored.
//
// ```yaml
// multi:
//
//	priorities:
//	- pool:
//	  - azureOpenai:
//	      deploymentName: gpt-4o-mini
//	      apiVersion: 2024-02-15-preview
//	      endpoint: ai-gateway.openai.azure.com
//	      authToken:
//	        secretRef:
//	          name: azure-secret
//	          namespace: gloo-system
//	- pool:
//	  - azureOpenai:
//	      deploymentName: gpt-4o-mini-2
//	      apiVersion: 2024-02-15-preview
//	      endpoint: ai-gateway-2.openai.azure.com
//	      authToken:
//	        secretRef:
//	          name: azure-secret-2
//	          namespace: gloo-system
//
// ```
type UpstreamSpec_MultiPool struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The order of `pool` entries within this section defines the priority of the backend endpoints.
	Priorities    []*UpstreamSpec_MultiPool_Priority `protobuf:"bytes,1,rep,name=priorities,proto3" json:"priorities,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_MultiPool) Reset() {
	*x = UpstreamSpec_MultiPool{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_MultiPool) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_MultiPool) ProtoMessage() {}

func (x *UpstreamSpec_MultiPool) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_MultiPool.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_MultiPool) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 10}
}

func (x *UpstreamSpec_MultiPool) GetPriorities() []*UpstreamSpec_MultiPool_Priority {
	if x != nil {
		return x.Priorities
	}
	return nil
}

// An entry represeting an LLM provider backend that the AI Gateway routes requests to.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_MultiPool_Backend struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Llm:
	//
	//	*UpstreamSpec_MultiPool_Backend_Openai
	//	*UpstreamSpec_MultiPool_Backend_Mistral
	//	*UpstreamSpec_MultiPool_Backend_Anthropic
	//	*UpstreamSpec_MultiPool_Backend_AzureOpenai
	//	*UpstreamSpec_MultiPool_Backend_Gemini
	//	*UpstreamSpec_MultiPool_Backend_VertexAi
	//	*UpstreamSpec_MultiPool_Backend_Bedrock
	Llm           isUpstreamSpec_MultiPool_Backend_Llm `protobuf_oneof:"llm"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_MultiPool_Backend) Reset() {
	*x = UpstreamSpec_MultiPool_Backend{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_MultiPool_Backend) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_MultiPool_Backend) ProtoMessage() {}

func (x *UpstreamSpec_MultiPool_Backend) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_MultiPool_Backend.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_MultiPool_Backend) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 10, 0}
}

func (x *UpstreamSpec_MultiPool_Backend) GetLlm() isUpstreamSpec_MultiPool_Backend_Llm {
	if x != nil {
		return x.Llm
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetOpenai() *UpstreamSpec_OpenAI {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_Openai); ok {
			return x.Openai
		}
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetMistral() *UpstreamSpec_Mistral {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_Mistral); ok {
			return x.Mistral
		}
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetAnthropic() *UpstreamSpec_Anthropic {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_Anthropic); ok {
			return x.Anthropic
		}
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetAzureOpenai() *UpstreamSpec_AzureOpenAI {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_AzureOpenai); ok {
			return x.AzureOpenai
		}
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetGemini() *UpstreamSpec_Gemini {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_Gemini); ok {
			return x.Gemini
		}
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetVertexAi() *UpstreamSpec_VertexAI {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_VertexAi); ok {
			return x.VertexAi
		}
	}
	return nil
}

func (x *UpstreamSpec_MultiPool_Backend) GetBedrock() *UpstreamSpec_Bedrock {
	if x != nil {
		if x, ok := x.Llm.(*UpstreamSpec_MultiPool_Backend_Bedrock); ok {
			return x.Bedrock
		}
	}
	return nil
}

type isUpstreamSpec_MultiPool_Backend_Llm interface {
	isUpstreamSpec_MultiPool_Backend_Llm()
}

type UpstreamSpec_MultiPool_Backend_Openai struct {
	// Configure an [OpenAI](https://platform.openai.com/docs/overview) backend.
	Openai *UpstreamSpec_OpenAI `protobuf:"bytes,1,opt,name=openai,proto3,oneof"`
}

type UpstreamSpec_MultiPool_Backend_Mistral struct {
	// Configure a [Mistral AI](https://docs.mistral.ai/getting-started/quickstart/) backend.
	Mistral *UpstreamSpec_Mistral `protobuf:"bytes,2,opt,name=mistral,proto3,oneof"`
}

type UpstreamSpec_MultiPool_Backend_Anthropic struct {
	// Configure an [Anthropic](https://docs.anthropic.com/en/release-notes/api) backend.
	Anthropic *UpstreamSpec_Anthropic `protobuf:"bytes,3,opt,name=anthropic,proto3,oneof"`
}

type UpstreamSpec_MultiPool_Backend_AzureOpenai struct {
	// Configure an [Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/) backend.
	AzureOpenai *UpstreamSpec_AzureOpenAI `protobuf:"bytes,4,opt,name=azure_openai,json=azureOpenai,proto3,oneof"`
}

type UpstreamSpec_MultiPool_Backend_Gemini struct {
	// Configure a [Gemini](https://ai.google.dev/gemini-api/docs) backend.
	Gemini *UpstreamSpec_Gemini `protobuf:"bytes,5,opt,name=gemini,proto3,oneof"`
}

type UpstreamSpec_MultiPool_Backend_VertexAi struct {
	// Configure a [Vertex AI](https://cloud.google.com/vertex-ai/docs) backend.
	VertexAi *UpstreamSpec_VertexAI `protobuf:"bytes,6,opt,name=vertex_ai,json=vertexAi,proto3,oneof"`
}

type UpstreamSpec_MultiPool_Backend_Bedrock struct {
	// Configure a [Bedrock](https://aws.amazon.com/bedrock/) backend.
	Bedrock *UpstreamSpec_Bedrock `protobuf:"bytes,7,opt,name=bedrock,proto3,oneof"`
}

func (*UpstreamSpec_MultiPool_Backend_Openai) isUpstreamSpec_MultiPool_Backend_Llm() {}

func (*UpstreamSpec_MultiPool_Backend_Mistral) isUpstreamSpec_MultiPool_Backend_Llm() {}

func (*UpstreamSpec_MultiPool_Backend_Anthropic) isUpstreamSpec_MultiPool_Backend_Llm() {}

func (*UpstreamSpec_MultiPool_Backend_AzureOpenai) isUpstreamSpec_MultiPool_Backend_Llm() {}

func (*UpstreamSpec_MultiPool_Backend_Gemini) isUpstreamSpec_MultiPool_Backend_Llm() {}

func (*UpstreamSpec_MultiPool_Backend_VertexAi) isUpstreamSpec_MultiPool_Backend_Llm() {}

func (*UpstreamSpec_MultiPool_Backend_Bedrock) isUpstreamSpec_MultiPool_Backend_Llm() {}

// The order of `pool` entries within this section defines the priority of the backend endpoints.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type UpstreamSpec_MultiPool_Priority struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A list of LLM provider backends within a single endpoint pool entry.
	Pool          []*UpstreamSpec_MultiPool_Backend `protobuf:"bytes,1,rep,name=pool,proto3" json:"pool,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UpstreamSpec_MultiPool_Priority) Reset() {
	*x = UpstreamSpec_MultiPool_Priority{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UpstreamSpec_MultiPool_Priority) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UpstreamSpec_MultiPool_Priority) ProtoMessage() {}

func (x *UpstreamSpec_MultiPool_Priority) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UpstreamSpec_MultiPool_Priority.ProtoReflect.Descriptor instead.
func (*UpstreamSpec_MultiPool_Priority) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{1, 10, 1}
}

func (x *UpstreamSpec_MultiPool_Priority) GetPool() []*UpstreamSpec_MultiPool_Backend {
	if x != nil {
		return x.Pool
	}
	return nil
}

// Embedding settings for the OpenAI provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type Embedding_OpenAI struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*Embedding_OpenAI_AuthToken
	AuthTokenSource isEmbedding_OpenAI_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *Embedding_OpenAI) Reset() {
	*x = Embedding_OpenAI{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Embedding_OpenAI) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Embedding_OpenAI) ProtoMessage() {}

func (x *Embedding_OpenAI) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Embedding_OpenAI.ProtoReflect.Descriptor instead.
func (*Embedding_OpenAI) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{5, 0}
}

func (x *Embedding_OpenAI) GetAuthTokenSource() isEmbedding_OpenAI_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *Embedding_OpenAI) GetAuthToken() *SingleAuthToken {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*Embedding_OpenAI_AuthToken); ok {
			return x.AuthToken
		}
	}
	return nil
}

type isEmbedding_OpenAI_AuthTokenSource interface {
	isEmbedding_OpenAI_AuthTokenSource()
}

type Embedding_OpenAI_AuthToken struct {
	// The authorization token that the AI gateway uses to access the OpenAI API.
	// This token is automatically sent in the `Authorization` header of the
	// request and prefixed with `Bearer`.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3,oneof"`
}

func (*Embedding_OpenAI_AuthToken) isEmbedding_OpenAI_AuthTokenSource() {}

// Embedding settings for the Azure OpenAI provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type Embedding_AzureOpenAI struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*Embedding_AzureOpenAI_AuthToken
	AuthTokenSource isEmbedding_AzureOpenAI_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	// The version of the Azure OpenAI API to use.
	// For more information, see the [Azure OpenAI API version reference](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs).
	ApiVersion string `protobuf:"bytes,2,opt,name=api_version,json=apiVersion,proto3" json:"api_version,omitempty"`
	// The endpoint for the Azure OpenAI API to use, such as `my-endpoint.openai.azure.com`.
	// If the scheme is not included, it is added.
	Endpoint string `protobuf:"bytes,3,opt,name=endpoint,proto3" json:"endpoint,omitempty"`
	// The name of the Azure OpenAI model deployment to use.
	// For more information, see the [Azure OpenAI model docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models).
	DeploymentName string `protobuf:"bytes,4,opt,name=deployment_name,json=deploymentName,proto3" json:"deployment_name,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *Embedding_AzureOpenAI) Reset() {
	*x = Embedding_AzureOpenAI{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Embedding_AzureOpenAI) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Embedding_AzureOpenAI) ProtoMessage() {}

func (x *Embedding_AzureOpenAI) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Embedding_AzureOpenAI.ProtoReflect.Descriptor instead.
func (*Embedding_AzureOpenAI) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{5, 1}
}

func (x *Embedding_AzureOpenAI) GetAuthTokenSource() isEmbedding_AzureOpenAI_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *Embedding_AzureOpenAI) GetAuthToken() *SingleAuthToken {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*Embedding_AzureOpenAI_AuthToken); ok {
			return x.AuthToken
		}
	}
	return nil
}

func (x *Embedding_AzureOpenAI) GetApiVersion() string {
	if x != nil {
		return x.ApiVersion
	}
	return ""
}

func (x *Embedding_AzureOpenAI) GetEndpoint() string {
	if x != nil {
		return x.Endpoint
	}
	return ""
}

func (x *Embedding_AzureOpenAI) GetDeploymentName() string {
	if x != nil {
		return x.DeploymentName
	}
	return ""
}

type isEmbedding_AzureOpenAI_AuthTokenSource interface {
	isEmbedding_AzureOpenAI_AuthTokenSource()
}

type Embedding_AzureOpenAI_AuthToken struct {
	// The authorization token that the AI gateway uses to access the Azure OpenAI API.
	// This token is automatically sent in the `api-key` header of the request.
	AuthToken *SingleAuthToken `protobuf:"bytes,1,opt,name=auth_token,json=authToken,proto3,oneof"`
}

func (*Embedding_AzureOpenAI_AuthToken) isEmbedding_AzureOpenAI_AuthTokenSource() {}

// Settings for a Redis database.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type SemanticCache_Redis struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Connection string to the Redis database, such as `redis://172.17.0.1:6379`.
	ConnectionString string `protobuf:"bytes,1,opt,name=connection_string,json=connectionString,proto3" json:"connection_string,omitempty"`
	// Similarity score threshold value between 0.0 and 1.0 that determines how similar
	// two queries must be in order to return a cached result.
	// The lower the number, the more similar the queries must be for a cache hit.
	//
	// +kubebuilder:validation:Minimum=0
	// +kubebuilder:validation:Maximum=1
	// Deprecated: Prefer setting the distance threshold in the RouteOptions.SemanticCache resource.
	ScoreThreshold float32 `protobuf:"fixed32,2,opt,name=score_threshold,json=scoreThreshold,proto3" json:"score_threshold,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *SemanticCache_Redis) Reset() {
	*x = SemanticCache_Redis{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SemanticCache_Redis) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SemanticCache_Redis) ProtoMessage() {}

func (x *SemanticCache_Redis) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SemanticCache_Redis.ProtoReflect.Descriptor instead.
func (*SemanticCache_Redis) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{6, 0}
}

func (x *SemanticCache_Redis) GetConnectionString() string {
	if x != nil {
		return x.ConnectionString
	}
	return ""
}

func (x *SemanticCache_Redis) GetScoreThreshold() float32 {
	if x != nil {
		return x.ScoreThreshold
	}
	return 0
}

// Settings for a Weaviate database.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type SemanticCache_Weaviate struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Connection string to the Weaviate database.
	// Do not include the scheme. For example, the format
	// `weaviate.my-ns.svc.cluster.local` is correct. The format
	// `http://weaviate.my-ns.svc.cluster.local`, which includes the scheme, is incorrect.
	Host string `protobuf:"bytes,1,opt,name=host,proto3" json:"host,omitempty"`
	// HTTP port to use. If unset, defaults to `8080`.
	HttpPort uint32 `protobuf:"varint,2,opt,name=http_port,json=httpPort,proto3" json:"http_port,omitempty"`
	// GRPC port to use. If unset, defaults to `50051`.
	GrpcPort uint32 `protobuf:"varint,3,opt,name=grpc_port,json=grpcPort,proto3" json:"grpc_port,omitempty"`
	// Whether to use a secure connection. Defaults to `true`.
	Insecure      bool `protobuf:"varint,4,opt,name=insecure,proto3" json:"insecure,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SemanticCache_Weaviate) Reset() {
	*x = SemanticCache_Weaviate{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[27]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SemanticCache_Weaviate) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SemanticCache_Weaviate) ProtoMessage() {}

func (x *SemanticCache_Weaviate) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[27]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SemanticCache_Weaviate.ProtoReflect.Descriptor instead.
func (*SemanticCache_Weaviate) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{6, 1}
}

func (x *SemanticCache_Weaviate) GetHost() string {
	if x != nil {
		return x.Host
	}
	return ""
}

func (x *SemanticCache_Weaviate) GetHttpPort() uint32 {
	if x != nil {
		return x.HttpPort
	}
	return 0
}

func (x *SemanticCache_Weaviate) GetGrpcPort() uint32 {
	if x != nil {
		return x.GrpcPort
	}
	return 0
}

func (x *SemanticCache_Weaviate) GetInsecure() bool {
	if x != nil {
		return x.Insecure
	}
	return false
}

// Data store from which to cache the request and response pairs.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type SemanticCache_DataStore struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Datastore:
	//
	//	*SemanticCache_DataStore_Redis
	//	*SemanticCache_DataStore_Weaviate
	Datastore     isSemanticCache_DataStore_Datastore `protobuf_oneof:"datastore"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SemanticCache_DataStore) Reset() {
	*x = SemanticCache_DataStore{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[28]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SemanticCache_DataStore) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SemanticCache_DataStore) ProtoMessage() {}

func (x *SemanticCache_DataStore) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[28]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SemanticCache_DataStore.ProtoReflect.Descriptor instead.
func (*SemanticCache_DataStore) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{6, 2}
}

func (x *SemanticCache_DataStore) GetDatastore() isSemanticCache_DataStore_Datastore {
	if x != nil {
		return x.Datastore
	}
	return nil
}

func (x *SemanticCache_DataStore) GetRedis() *SemanticCache_Redis {
	if x != nil {
		if x, ok := x.Datastore.(*SemanticCache_DataStore_Redis); ok {
			return x.Redis
		}
	}
	return nil
}

func (x *SemanticCache_DataStore) GetWeaviate() *SemanticCache_Weaviate {
	if x != nil {
		if x, ok := x.Datastore.(*SemanticCache_DataStore_Weaviate); ok {
			return x.Weaviate
		}
	}
	return nil
}

type isSemanticCache_DataStore_Datastore interface {
	isSemanticCache_DataStore_Datastore()
}

type SemanticCache_DataStore_Redis struct {
	// Settings for a Redis database.
	Redis *SemanticCache_Redis `protobuf:"bytes,1,opt,name=redis,proto3,oneof"`
}

type SemanticCache_DataStore_Weaviate struct {
	// Settings for a Weaviate database.
	Weaviate *SemanticCache_Weaviate `protobuf:"bytes,2,opt,name=weaviate,proto3,oneof"`
}

func (*SemanticCache_DataStore_Redis) isSemanticCache_DataStore_Datastore() {}

func (*SemanticCache_DataStore_Weaviate) isSemanticCache_DataStore_Datastore() {}

// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type RAG_DataStore struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Datastore:
	//
	//	*RAG_DataStore_Postgres
	Datastore     isRAG_DataStore_Datastore `protobuf_oneof:"datastore"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RAG_DataStore) Reset() {
	*x = RAG_DataStore{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[29]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RAG_DataStore) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RAG_DataStore) ProtoMessage() {}

func (x *RAG_DataStore) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[29]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RAG_DataStore.ProtoReflect.Descriptor instead.
func (*RAG_DataStore) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{7, 0}
}

func (x *RAG_DataStore) GetDatastore() isRAG_DataStore_Datastore {
	if x != nil {
		return x.Datastore
	}
	return nil
}

func (x *RAG_DataStore) GetPostgres() *Postgres {
	if x != nil {
		if x, ok := x.Datastore.(*RAG_DataStore_Postgres); ok {
			return x.Postgres
		}
	}
	return nil
}

type isRAG_DataStore_Datastore interface {
	isRAG_DataStore_Datastore()
}

type RAG_DataStore_Postgres struct {
	// Configuration settings for a Postgres datastore.
	Postgres *Postgres `protobuf:"bytes,1,opt,name=postgres,proto3,oneof"`
}

func (*RAG_DataStore_Postgres) isRAG_DataStore_Datastore() {}

// An entry for a message to prepend or append to each prompt.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptEnrichment_Message struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Role of the message. The available roles depend on the backend
	// LLM provider model, such as `SYSTEM` or `USER` in the OpenAI API.
	Role string `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"`
	// String content of the message.
	Content       string `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptEnrichment_Message) Reset() {
	*x = AIPromptEnrichment_Message{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[30]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptEnrichment_Message) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptEnrichment_Message) ProtoMessage() {}

func (x *AIPromptEnrichment_Message) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[30]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptEnrichment_Message.ProtoReflect.Descriptor instead.
func (*AIPromptEnrichment_Message) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{8, 0}
}

func (x *AIPromptEnrichment_Message) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *AIPromptEnrichment_Message) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

// Regular expression (regex) matching for prompt guards and data masking.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Regex struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A list of regex patterns to match against the request or response.
	// Matches and built-ins are additive.
	Matches []*AIPromptGuard_Regex_RegexMatch `protobuf:"bytes,1,rep,name=matches,proto3" json:"matches,omitempty"`
	// A list of built-in regex patterns to match against the request or response.
	// Matches and built-ins are additive.
	Builtins []AIPromptGuard_Regex_BuiltIn `protobuf:"varint,2,rep,packed,name=builtins,proto3,enum=ai.options.gloo.solo.io.AIPromptGuard_Regex_BuiltIn" json:"builtins,omitempty"`
	// The action to take if a regex pattern is matched in a request or response.
	// This setting applies only to request matches. Response matches are always masked by default.
	Action        AIPromptGuard_Regex_Action `protobuf:"varint,3,opt,name=action,proto3,enum=ai.options.gloo.solo.io.AIPromptGuard_Regex_Action" json:"action,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Regex) Reset() {
	*x = AIPromptGuard_Regex{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[31]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Regex) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Regex) ProtoMessage() {}

func (x *AIPromptGuard_Regex) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[31]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Regex.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Regex) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 0}
}

func (x *AIPromptGuard_Regex) GetMatches() []*AIPromptGuard_Regex_RegexMatch {
	if x != nil {
		return x.Matches
	}
	return nil
}

func (x *AIPromptGuard_Regex) GetBuiltins() []AIPromptGuard_Regex_BuiltIn {
	if x != nil {
		return x.Builtins
	}
	return nil
}

func (x *AIPromptGuard_Regex) GetAction() AIPromptGuard_Regex_Action {
	if x != nil {
		return x.Action
	}
	return AIPromptGuard_Regex_MASK
}

// Configure a webhook to forward requests or responses to for prompt guarding.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Webhook struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Host to send the traffic to.
	Host string `protobuf:"bytes,1,opt,name=host,proto3" json:"host,omitempty"`
	// Port to send the traffic to
	Port uint32 `protobuf:"varint,2,opt,name=port,proto3" json:"port,omitempty"`
	// Headers to forward with the request to the webhook.
	ForwardHeaders []*AIPromptGuard_Webhook_HeaderMatch `protobuf:"bytes,3,rep,name=forwardHeaders,proto3" json:"forwardHeaders,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *AIPromptGuard_Webhook) Reset() {
	*x = AIPromptGuard_Webhook{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[32]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Webhook) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Webhook) ProtoMessage() {}

func (x *AIPromptGuard_Webhook) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[32]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Webhook.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Webhook) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 1}
}

func (x *AIPromptGuard_Webhook) GetHost() string {
	if x != nil {
		return x.Host
	}
	return ""
}

func (x *AIPromptGuard_Webhook) GetPort() uint32 {
	if x != nil {
		return x.Port
	}
	return 0
}

func (x *AIPromptGuard_Webhook) GetForwardHeaders() []*AIPromptGuard_Webhook_HeaderMatch {
	if x != nil {
		return x.ForwardHeaders
	}
	return nil
}

// Pass prompt data through an external moderation model endpoint,
// which compares the request prompt input to predefined content rules.
// Any requests that are routed through Gloo AI Gateway pass through the
// moderation model that you specify. If the content is identified as harmful
// according to the model's content rules, the request is automatically rejected.
//
// You can configure an moderation endpoint either as a standalone prompt guard setting
// or in addition to other request and response guard settings.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Moderation struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Pass prompt data through an external moderation model endpoint,
	// which compares the request prompt input to predefined content rules.
	//
	// Types that are valid to be assigned to Moderation:
	//
	//	*AIPromptGuard_Moderation_Openai
	Moderation    isAIPromptGuard_Moderation_Moderation `protobuf_oneof:"moderation"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Moderation) Reset() {
	*x = AIPromptGuard_Moderation{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[33]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Moderation) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Moderation) ProtoMessage() {}

func (x *AIPromptGuard_Moderation) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[33]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Moderation.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Moderation) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 2}
}

func (x *AIPromptGuard_Moderation) GetModeration() isAIPromptGuard_Moderation_Moderation {
	if x != nil {
		return x.Moderation
	}
	return nil
}

func (x *AIPromptGuard_Moderation) GetOpenai() *AIPromptGuard_Moderation_OpenAI {
	if x != nil {
		if x, ok := x.Moderation.(*AIPromptGuard_Moderation_Openai); ok {
			return x.Openai
		}
	}
	return nil
}

type isAIPromptGuard_Moderation_Moderation interface {
	isAIPromptGuard_Moderation_Moderation()
}

type AIPromptGuard_Moderation_Openai struct {
	// Configure an OpenAI moderation endpoint.
	Openai *AIPromptGuard_Moderation_OpenAI `protobuf:"bytes,1,opt,name=openai,proto3,oneof"`
}

func (*AIPromptGuard_Moderation_Openai) isAIPromptGuard_Moderation_Moderation() {}

// Prompt guards to apply to requests sent by the client.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Request struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A custom response message to return to the client. If not specified, defaults to
	// "The request was rejected due to inappropriate content".
	CustomResponse *AIPromptGuard_Request_CustomResponse `protobuf:"bytes,1,opt,name=custom_response,json=customResponse,proto3" json:"custom_response,omitempty"`
	// Regular expression (regex) matching for prompt guards and data masking.
	Regex *AIPromptGuard_Regex `protobuf:"bytes,2,opt,name=regex,proto3" json:"regex,omitempty"`
	// Configure a webhook to forward requests to for prompt guarding.
	Webhook *AIPromptGuard_Webhook `protobuf:"bytes,3,opt,name=webhook,proto3" json:"webhook,omitempty"`
	// Pass prompt data through an external moderation model endpoint,
	// which compares the request prompt input to predefined content rules.
	Moderation    *AIPromptGuard_Moderation `protobuf:"bytes,4,opt,name=moderation,proto3" json:"moderation,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Request) Reset() {
	*x = AIPromptGuard_Request{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[34]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Request) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Request) ProtoMessage() {}

func (x *AIPromptGuard_Request) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[34]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Request.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Request) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 3}
}

func (x *AIPromptGuard_Request) GetCustomResponse() *AIPromptGuard_Request_CustomResponse {
	if x != nil {
		return x.CustomResponse
	}
	return nil
}

func (x *AIPromptGuard_Request) GetRegex() *AIPromptGuard_Regex {
	if x != nil {
		return x.Regex
	}
	return nil
}

func (x *AIPromptGuard_Request) GetWebhook() *AIPromptGuard_Webhook {
	if x != nil {
		return x.Webhook
	}
	return nil
}

func (x *AIPromptGuard_Request) GetModeration() *AIPromptGuard_Moderation {
	if x != nil {
		return x.Moderation
	}
	return nil
}

// Prompt guards to apply to responses returned by the LLM provider.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Response struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Regular expression (regex) matching for prompt guards and data masking.
	Regex *AIPromptGuard_Regex `protobuf:"bytes,1,opt,name=regex,proto3" json:"regex,omitempty"`
	// Configure a webhook to forward responses to for prompt guarding.
	Webhook       *AIPromptGuard_Webhook `protobuf:"bytes,2,opt,name=webhook,proto3" json:"webhook,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Response) Reset() {
	*x = AIPromptGuard_Response{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[35]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Response) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Response) ProtoMessage() {}

func (x *AIPromptGuard_Response) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[35]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Response.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Response) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 4}
}

func (x *AIPromptGuard_Response) GetRegex() *AIPromptGuard_Regex {
	if x != nil {
		return x.Regex
	}
	return nil
}

func (x *AIPromptGuard_Response) GetWebhook() *AIPromptGuard_Webhook {
	if x != nil {
		return x.Webhook
	}
	return nil
}

// Regular expression (regex) matching for prompt guards and data masking.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Regex_RegexMatch struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The regex pattern to match against the request or response.
	Pattern string `protobuf:"bytes,1,opt,name=pattern,proto3" json:"pattern,omitempty"`
	// An optional name for this match, which can be used for debugging purposes.
	Name          string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Regex_RegexMatch) Reset() {
	*x = AIPromptGuard_Regex_RegexMatch{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[36]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Regex_RegexMatch) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Regex_RegexMatch) ProtoMessage() {}

func (x *AIPromptGuard_Regex_RegexMatch) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[36]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Regex_RegexMatch.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Regex_RegexMatch) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 0, 0}
}

func (x *AIPromptGuard_Regex_RegexMatch) GetPattern() string {
	if x != nil {
		return x.Pattern
	}
	return ""
}

func (x *AIPromptGuard_Regex_RegexMatch) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

// Describes how to match a given string in HTTP headers. Match is case-sensitive.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Webhook_HeaderMatch struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The header key string to match against.
	Key string `protobuf:"bytes,1,opt,name=key,proto3" json:"key,omitempty"`
	// The type of match to use.
	MatchType     AIPromptGuard_Webhook_HeaderMatch_MatchType `protobuf:"varint,2,opt,name=match_type,json=matchType,proto3,enum=ai.options.gloo.solo.io.AIPromptGuard_Webhook_HeaderMatch_MatchType" json:"match_type,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Webhook_HeaderMatch) Reset() {
	*x = AIPromptGuard_Webhook_HeaderMatch{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[37]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Webhook_HeaderMatch) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Webhook_HeaderMatch) ProtoMessage() {}

func (x *AIPromptGuard_Webhook_HeaderMatch) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[37]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Webhook_HeaderMatch.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Webhook_HeaderMatch) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 1, 0}
}

func (x *AIPromptGuard_Webhook_HeaderMatch) GetKey() string {
	if x != nil {
		return x.Key
	}
	return ""
}

func (x *AIPromptGuard_Webhook_HeaderMatch) GetMatchType() AIPromptGuard_Webhook_HeaderMatch_MatchType {
	if x != nil {
		return x.MatchType
	}
	return AIPromptGuard_Webhook_HeaderMatch_EXACT
}

// Configure an OpenAI moderation endpoint.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Moderation_OpenAI struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The name of the OpenAI moderation model to use. Defaults to
	// [`omni-moderation-latest`](https://platform.openai.com/docs/guides/moderation).
	Model string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	// The authorization token that the AI gateway uses
	// to access the OpenAI moderation model.
	//
	// Types that are valid to be assigned to AuthTokenSource:
	//
	//	*AIPromptGuard_Moderation_OpenAI_AuthToken
	AuthTokenSource isAIPromptGuard_Moderation_OpenAI_AuthTokenSource `protobuf_oneof:"auth_token_source"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *AIPromptGuard_Moderation_OpenAI) Reset() {
	*x = AIPromptGuard_Moderation_OpenAI{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[38]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Moderation_OpenAI) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Moderation_OpenAI) ProtoMessage() {}

func (x *AIPromptGuard_Moderation_OpenAI) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[38]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Moderation_OpenAI.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Moderation_OpenAI) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 2, 0}
}

func (x *AIPromptGuard_Moderation_OpenAI) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *AIPromptGuard_Moderation_OpenAI) GetAuthTokenSource() isAIPromptGuard_Moderation_OpenAI_AuthTokenSource {
	if x != nil {
		return x.AuthTokenSource
	}
	return nil
}

func (x *AIPromptGuard_Moderation_OpenAI) GetAuthToken() *SingleAuthToken {
	if x != nil {
		if x, ok := x.AuthTokenSource.(*AIPromptGuard_Moderation_OpenAI_AuthToken); ok {
			return x.AuthToken
		}
	}
	return nil
}

type isAIPromptGuard_Moderation_OpenAI_AuthTokenSource interface {
	isAIPromptGuard_Moderation_OpenAI_AuthTokenSource()
}

type AIPromptGuard_Moderation_OpenAI_AuthToken struct {
	// The authorization token that the AI gateway uses
	// to access the OpenAI moderation model.
	AuthToken *SingleAuthToken `protobuf:"bytes,2,opt,name=auth_token,json=authToken,proto3,oneof"`
}

func (*AIPromptGuard_Moderation_OpenAI_AuthToken) isAIPromptGuard_Moderation_OpenAI_AuthTokenSource() {
}

// A custom response to return to the client if request content
// is matched against a regex pattern and the action is `REJECT`.
// {{% notice note %}}
// The AI API is supported only in [Gloo Gateway (Kubernetes Gateway API)](https://docs.solo.io/gateway/main/ai/). It is not supported with the Gloo Edge API.
// {{% /notice %}}
type AIPromptGuard_Request_CustomResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A custom response message to return to the client. If not specified, defaults to
	// "The request was rejected due to inappropriate content".
	Message string `protobuf:"bytes,1,opt,name=message,proto3" json:"message,omitempty"`
	// The status code to return to the client.
	StatusCode    uint32 `protobuf:"varint,2,opt,name=status_code,json=statusCode,proto3" json:"status_code,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AIPromptGuard_Request_CustomResponse) Reset() {
	*x = AIPromptGuard_Request_CustomResponse{}
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[39]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AIPromptGuard_Request_CustomResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AIPromptGuard_Request_CustomResponse) ProtoMessage() {}

func (x *AIPromptGuard_Request_CustomResponse) ProtoReflect() protoreflect.Message {
	mi := &file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[39]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AIPromptGuard_Request_CustomResponse.ProtoReflect.Descriptor instead.
func (*AIPromptGuard_Request_CustomResponse) Descriptor() ([]byte, []int) {
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP(), []int{9, 3, 0}
}

func (x *AIPromptGuard_Request_CustomResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *AIPromptGuard_Request_CustomResponse) GetStatusCode() uint32 {
	if x != nil {
		return x.StatusCode
	}
	return 0
}

var File_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto protoreflect.FileDescriptor

const file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDesc = "" +
	"\n" +
	"Kgithub.com/solo-io/gloo/projects/gloo/api/v1/enterprise/options/ai/ai.proto\x12\x17ai.options.gloo.solo.io\x1a,github.com/solo-io/solo-kit/api/v1/ref.proto\x1a\x1cgoogle/protobuf/struct.proto\x1a\x1egoogle/protobuf/wrappers.proto\x1a\x12extproto/ext.proto\"\xe5\x01\n" +
	"\x0fSingleAuthToken\x12\x18\n" +
	"\x06inline\x18\x01 \x01(\tH\x00R\x06inline\x12:\n" +
	"\n" +
	"secret_ref\x18\x02 \x01(\v2\x19.core.solo.io.ResourceRefH\x00R\tsecretRef\x12X\n" +
	"\vpassthrough\x18\x03 \x01(\v24.ai.options.gloo.solo.io.SingleAuthToken.PassthroughH\x00R\vpassthrough\x1a\r\n" +
	"\vPassthroughB\x13\n" +
	"\x11auth_token_source\"\x97\x1b\n" +
	"\fUpstreamSpec\x12F\n" +
	"\x06openai\x18\x01 \x01(\v2,.ai.options.gloo.solo.io.UpstreamSpec.OpenAIH\x00R\x06openai\x12I\n" +
	"\amistral\x18\x02 \x01(\v2-.ai.options.gloo.solo.io.UpstreamSpec.MistralH\x00R\amistral\x12O\n" +
	"\tanthropic\x18\x03 \x01(\v2/.ai.options.gloo.solo.io.UpstreamSpec.AnthropicH\x00R\tanthropic\x12V\n" +
	"\fazure_openai\x18\x04 \x01(\v21.ai.options.gloo.solo.io.UpstreamSpec.AzureOpenAIH\x00R\vazureOpenai\x12G\n" +
	"\x05multi\x18\x05 \x01(\v2/.ai.options.gloo.solo.io.UpstreamSpec.MultiPoolH\x00R\x05multi\x12F\n" +
	"\x06gemini\x18\x06 \x01(\v2,.ai.options.gloo.solo.io.UpstreamSpec.GeminiH\x00R\x06gemini\x12M\n" +
	"\tvertex_ai\x18\a \x01(\v2..ai.options.gloo.solo.io.UpstreamSpec.VertexAIH\x00R\bvertexAi\x12I\n" +
	"\abedrock\x18\b \x01(\v2-.ai.options.gloo.solo.io.UpstreamSpec.BedrockH\x00R\abedrock\x1an\n" +
	"\n" +
	"CustomHost\x12\x12\n" +
	"\x04host\x18\x01 \x01(\tR\x04host\x12\x12\n" +
	"\x04port\x18\x02 \x01(\rR\x04port\x128\n" +
	"\bhostname\x18\x03 \x01(\v2\x1c.google.protobuf.StringValueR\bhostname\x1a\xba\x01\n" +
	"\x06OpenAI\x12G\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenR\tauthToken\x12Q\n" +
	"\vcustom_host\x18\x02 \x01(\v20.ai.options.gloo.solo.io.UpstreamSpec.CustomHostR\n" +
	"customHost\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\x1a\xd3\x01\n" +
	"\vAzureOpenAI\x12I\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenH\x00R\tauthToken\x12\x1a\n" +
	"\bendpoint\x18\x02 \x01(\tR\bendpoint\x12'\n" +
	"\x0fdeployment_name\x18\x03 \x01(\tR\x0edeploymentName\x12\x1f\n" +
	"\vapi_version\x18\x04 \x01(\tR\n" +
	"apiVersionB\x13\n" +
	"\x11auth_token_source\x1a\x9f\x01\n" +
	"\x06Gemini\x12I\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenH\x00R\tauthToken\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12\x1f\n" +
	"\vapi_version\x18\x03 \x01(\tR\n" +
	"apiVersionB\x13\n" +
	"\x11auth_token_source\x1a\xb5\x03\n" +
	"\bVertexAI\x12I\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenH\x00R\tauthToken\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12\x1f\n" +
	"\vapi_version\x18\x03 \x01(\tR\n" +
	"apiVersion\x12\x1d\n" +
	"\n" +
	"project_id\x18\x04 \x01(\tR\tprojectId\x12\x1a\n" +
	"\blocation\x18\x05 \x01(\tR\blocation\x12\x1d\n" +
	"\n" +
	"model_path\x18\x06 \x01(\tR\tmodelPath\x12V\n" +
	"\tpublisher\x18\a \x01(\x0e28.ai.options.gloo.solo.io.UpstreamSpec.VertexAI.PublisherR\tpublisher\x12G\n" +
	"\vjson_schema\x18\b \x01(\x0e2&.ai.options.gloo.solo.io.ApiJsonSchemaR\n" +
	"jsonSchema\"\x17\n" +
	"\tPublisher\x12\n" +
	"\n" +
	"\x06GOOGLE\x10\x00B\x13\n" +
	"\x11auth_token_source\x1a\xbb\x01\n" +
	"\aMistral\x12G\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenR\tauthToken\x12Q\n" +
	"\vcustom_host\x18\x02 \x01(\v20.ai.options.gloo.solo.io.UpstreamSpec.CustomHostR\n" +
	"customHost\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\x1a\xd7\x01\n" +
	"\tAnthropic\x12G\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenR\tauthToken\x12Q\n" +
	"\vcustom_host\x18\x02 \x01(\v20.ai.options.gloo.solo.io.UpstreamSpec.CustomHostR\n" +
	"customHost\x12\x18\n" +
	"\aversion\x18\x03 \x01(\tR\aversion\x12\x14\n" +
	"\x05model\x18\x04 \x01(\tR\x05model\x1a\xf8\x01\n" +
	"\aBedrock\x12l\n" +
	"\x13credential_provider\x18\x01 \x01(\v2;.ai.options.gloo.solo.io.UpstreamSpec.AwsCredentialProviderR\x12credentialProvider\x12Q\n" +
	"\vcustom_host\x18\x02 \x01(\v20.ai.options.gloo.solo.io.UpstreamSpec.CustomHostR\n" +
	"customHost\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\x12\x16\n" +
	"\x06region\x18\x04 \x01(\tR\x06region\x1a\xb3\x01\n" +
	"\x15AwsCredentialProvider\x12:\n" +
	"\n" +
	"secret_ref\x18\x01 \x01(\v2\x19.core.solo.io.ResourceRefH\x00R\tsecretRef\x12I\n" +
	"\x06inline\x18\x02 \x01(\v2/.ai.options.gloo.solo.io.UpstreamSpec.AWSInlineH\x00R\x06inlineB\x13\n" +
	"\x11auth_token_source\x1a\x80\x01\n" +
	"\tAWSInline\x12\"\n" +
	"\raccess_key_id\x18\x01 \x01(\tR\vaccessKeyId\x12*\n" +
	"\x11secret_access_key\x18\x02 \x01(\tR\x0fsecretAccessKey\x12#\n" +
	"\rsession_token\x18\x03 \x01(\tR\fsessionToken\x1a\xef\x05\n" +
	"\tMultiPool\x12X\n" +
	"\n" +
	"priorities\x18\x01 \x03(\v28.ai.options.gloo.solo.io.UpstreamSpec.MultiPool.PriorityR\n" +
	"priorities\x1a\xae\x04\n" +
	"\aBackend\x12F\n" +
	"\x06openai\x18\x01 \x01(\v2,.ai.options.gloo.solo.io.UpstreamSpec.OpenAIH\x00R\x06openai\x12I\n" +
	"\amistral\x18\x02 \x01(\v2-.ai.options.gloo.solo.io.UpstreamSpec.MistralH\x00R\amistral\x12O\n" +
	"\tanthropic\x18\x03 \x01(\v2/.ai.options.gloo.solo.io.UpstreamSpec.AnthropicH\x00R\tanthropic\x12V\n" +
	"\fazure_openai\x18\x04 \x01(\v21.ai.options.gloo.solo.io.UpstreamSpec.AzureOpenAIH\x00R\vazureOpenai\x12F\n" +
	"\x06gemini\x18\x05 \x01(\v2,.ai.options.gloo.solo.io.UpstreamSpec.GeminiH\x00R\x06gemini\x12M\n" +
	"\tvertex_ai\x18\x06 \x01(\v2..ai.options.gloo.solo.io.UpstreamSpec.VertexAIH\x00R\bvertexAi\x12I\n" +
	"\abedrock\x18\a \x01(\v2-.ai.options.gloo.solo.io.UpstreamSpec.BedrockH\x00R\abedrockB\x05\n" +
	"\x03llm\x1aW\n" +
	"\bPriority\x12K\n" +
	"\x04pool\x18\x01 \x03(\v27.ai.options.gloo.solo.io.UpstreamSpec.MultiPool.BackendR\x04poolB\x05\n" +
	"\x03llm\"\xf2\x03\n" +
	"\rRouteSettings\x12X\n" +
	"\x11prompt_enrichment\x18\x01 \x01(\v2+.ai.options.gloo.solo.io.AIPromptEnrichmentR\x10promptEnrichment\x12I\n" +
	"\fprompt_guard\x18\x02 \x01(\v2&.ai.options.gloo.solo.io.AIPromptGuardR\vpromptGuard\x12.\n" +
	"\x03rag\x18\x03 \x01(\v2\x1c.ai.options.gloo.solo.io.RAGR\x03rag\x12M\n" +
	"\x0esemantic_cache\x18\x04 \x01(\v2&.ai.options.gloo.solo.io.SemanticCacheR\rsemanticCache\x12A\n" +
	"\bdefaults\x18\x05 \x03(\v2%.ai.options.gloo.solo.io.FieldDefaultR\bdefaults\x12O\n" +
	"\n" +
	"route_type\x18\x06 \x01(\x0e20.ai.options.gloo.solo.io.RouteSettings.RouteTypeR\trouteType\")\n" +
	"\tRouteType\x12\b\n" +
	"\x04CHAT\x10\x00\x12\x12\n" +
	"\x0eCHAT_STREAMING\x10\x01\"n\n" +
	"\fFieldDefault\x12\x14\n" +
	"\x05field\x18\x01 \x01(\tR\x05field\x12,\n" +
	"\x05value\x18\x02 \x01(\v2\x16.google.protobuf.ValueR\x05value\x12\x1a\n" +
	"\boverride\x18\x03 \x01(\bR\boverride\"`\n" +
	"\bPostgres\x12+\n" +
	"\x11connection_string\x18\x01 \x01(\tR\x10connectionString\x12'\n" +
	"\x0fcollection_name\x18\x02 \x01(\tR\x0ecollectionName\"\xf2\x03\n" +
	"\tEmbedding\x12C\n" +
	"\x06openai\x18\x01 \x01(\v2).ai.options.gloo.solo.io.Embedding.OpenAIH\x00R\x06openai\x12S\n" +
	"\fazure_openai\x18\x02 \x01(\v2..ai.options.gloo.solo.io.Embedding.AzureOpenAIH\x00R\vazureOpenai\x1ah\n" +
	"\x06OpenAI\x12I\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenH\x00R\tauthTokenB\x13\n" +
	"\x11auth_token_source\x1a\xd3\x01\n" +
	"\vAzureOpenAI\x12I\n" +
	"\n" +
	"auth_token\x18\x01 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenH\x00R\tauthToken\x12\x1f\n" +
	"\vapi_version\x18\x02 \x01(\tR\n" +
	"apiVersion\x12\x1a\n" +
	"\bendpoint\x18\x03 \x01(\tR\bendpoint\x12'\n" +
	"\x0fdeployment_name\x18\x04 \x01(\tR\x0edeploymentNameB\x13\n" +
	"\x11auth_token_sourceB\v\n" +
	"\tembedding\"\xcf\x05\n" +
	"\rSemanticCache\x12N\n" +
	"\tdatastore\x18\x01 \x01(\v20.ai.options.gloo.solo.io.SemanticCache.DataStoreR\tdatastore\x12@\n" +
	"\tembedding\x18\x02 \x01(\v2\".ai.options.gloo.solo.io.EmbeddingR\tembedding\x12\x10\n" +
	"\x03ttl\x18\x03 \x01(\rR\x03ttl\x12?\n" +
	"\x04mode\x18\x04 \x01(\x0e2+.ai.options.gloo.solo.io.SemanticCache.ModeR\x04mode\x12-\n" +
	"\x12distance_threshold\x18\x05 \x01(\x02R\x11distanceThreshold\x1a]\n" +
	"\x05Redis\x12+\n" +
	"\x11connection_string\x18\x01 \x01(\tR\x10connectionString\x12'\n" +
	"\x0fscore_threshold\x18\x02 \x01(\x02R\x0escoreThreshold\x1at\n" +
	"\bWeaviate\x12\x12\n" +
	"\x04host\x18\x01 \x01(\tR\x04host\x12\x1b\n" +
	"\thttp_port\x18\x02 \x01(\rR\bhttpPort\x12\x1b\n" +
	"\tgrpc_port\x18\x03 \x01(\rR\bgrpcPort\x12\x1a\n" +
	"\binsecure\x18\x04 \x01(\bR\binsecure\x1a\xad\x01\n" +
	"\tDataStore\x12D\n" +
	"\x05redis\x18\x01 \x01(\v2,.ai.options.gloo.solo.io.SemanticCache.RedisH\x00R\x05redis\x12M\n" +
	"\bweaviate\x18\x02 \x01(\v2/.ai.options.gloo.solo.io.SemanticCache.WeaviateH\x00R\bweaviateB\v\n" +
	"\tdatastore\"%\n" +
	"\x04Mode\x12\x0e\n" +
	"\n" +
	"READ_WRITE\x10\x00\x12\r\n" +
	"\tREAD_ONLY\x10\x01\"\x91\x02\n" +
	"\x03RAG\x12D\n" +
	"\tdatastore\x18\x01 \x01(\v2&.ai.options.gloo.solo.io.RAG.DataStoreR\tdatastore\x12@\n" +
	"\tembedding\x18\x02 \x01(\v2\".ai.options.gloo.solo.io.EmbeddingR\tembedding\x12'\n" +
	"\x0fprompt_template\x18\x03 \x01(\tR\x0epromptTemplate\x1aY\n" +
	"\tDataStore\x12?\n" +
	"\bpostgres\x18\x01 \x01(\v2!.ai.options.gloo.solo.io.PostgresH\x00R\bpostgresB\v\n" +
	"\tdatastore\"\xe9\x01\n" +
	"\x12AIPromptEnrichment\x12M\n" +
	"\aprepend\x18\x02 \x03(\v23.ai.options.gloo.solo.io.AIPromptEnrichment.MessageR\aprepend\x12K\n" +
	"\x06append\x18\x03 \x03(\v23.ai.options.gloo.solo.io.AIPromptEnrichment.MessageR\x06append\x1a7\n" +
	"\aMessage\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\"\xd6\r\n" +
	"\rAIPromptGuard\x12H\n" +
	"\arequest\x18\x01 \x01(\v2..ai.options.gloo.solo.io.AIPromptGuard.RequestR\arequest\x12K\n" +
	"\bresponse\x18\x02 \x01(\v2/.ai.options.gloo.solo.io.AIPromptGuard.ResponseR\bresponse\x1a\x97\x03\n" +
	"\x05Regex\x12Q\n" +
	"\amatches\x18\x01 \x03(\v27.ai.options.gloo.solo.io.AIPromptGuard.Regex.RegexMatchR\amatches\x12P\n" +
	"\bbuiltins\x18\x02 \x03(\x0e24.ai.options.gloo.solo.io.AIPromptGuard.Regex.BuiltInR\bbuiltins\x12K\n" +
	"\x06action\x18\x03 \x01(\x0e23.ai.options.gloo.solo.io.AIPromptGuard.Regex.ActionR\x06action\x1a:\n" +
	"\n" +
	"RegexMatch\x12\x18\n" +
	"\apattern\x18\x01 \x01(\tR\apattern\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\"@\n" +
	"\aBuiltIn\x12\a\n" +
	"\x03SSN\x10\x00\x12\x0f\n" +
	"\vCREDIT_CARD\x10\x01\x12\x10\n" +
	"\fPHONE_NUMBER\x10\x02\x12\t\n" +
	"\x05EMAIL\x10\x03\"\x1e\n" +
	"\x06Action\x12\b\n" +
	"\x04MASK\x10\x00\x12\n" +
	"\n" +
	"\x06REJECT\x10\x01\x1a\xe5\x02\n" +
	"\aWebhook\x12\x12\n" +
	"\x04host\x18\x01 \x01(\tR\x04host\x12\x12\n" +
	"\x04port\x18\x02 \x01(\rR\x04port\x12b\n" +
	"\x0eforwardHeaders\x18\x03 \x03(\v2:.ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatchR\x0eforwardHeaders\x1a\xcd\x01\n" +
	"\vHeaderMatch\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12c\n" +
	"\n" +
	"match_type\x18\x02 \x01(\x0e2D.ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatch.MatchTypeR\tmatchType\"G\n" +
	"\tMatchType\x12\t\n" +
	"\x05EXACT\x10\x00\x12\n" +
	"\n" +
	"\x06PREFIX\x10\x01\x12\n" +
	"\n" +
	"\x06SUFFIX\x10\x02\x12\f\n" +
	"\bCONTAINS\x10\x03\x12\t\n" +
	"\x05REGEX\x10\x04\x1a\xee\x01\n" +
	"\n" +
	"Moderation\x12R\n" +
	"\x06openai\x18\x01 \x01(\v28.ai.options.gloo.solo.io.AIPromptGuard.Moderation.OpenAIH\x00R\x06openai\x1a~\n" +
	"\x06OpenAI\x12\x14\n" +
	"\x05model\x18\x01 \x01(\tR\x05model\x12I\n" +
	"\n" +
	"auth_token\x18\x02 \x01(\v2(.ai.options.gloo.solo.io.SingleAuthTokenH\x00R\tauthTokenB\x13\n" +
	"\x11auth_token_sourceB\f\n" +
	"\n" +
	"moderation\x1a\x9f\x03\n" +
	"\aRequest\x12f\n" +
	"\x0fcustom_response\x18\x01 \x01(\v2=.ai.options.gloo.solo.io.AIPromptGuard.Request.CustomResponseR\x0ecustomResponse\x12B\n" +
	"\x05regex\x18\x02 \x01(\v2,.ai.options.gloo.solo.io.AIPromptGuard.RegexR\x05regex\x12H\n" +
	"\awebhook\x18\x03 \x01(\v2..ai.options.gloo.solo.io.AIPromptGuard.WebhookR\awebhook\x12Q\n" +
	"\n" +
	"moderation\x18\x04 \x01(\v21.ai.options.gloo.solo.io.AIPromptGuard.ModerationR\n" +
	"moderation\x1aK\n" +
	"\x0eCustomResponse\x12\x18\n" +
	"\amessage\x18\x01 \x01(\tR\amessage\x12\x1f\n" +
	"\vstatus_code\x18\x02 \x01(\rR\n" +
	"statusCode\x1a\x98\x01\n" +
	"\bResponse\x12B\n" +
	"\x05regex\x18\x01 \x01(\v2,.ai.options.gloo.solo.io.AIPromptGuard.RegexR\x05regex\x12H\n" +
	"\awebhook\x18\x02 \x01(\v2..ai.options.gloo.solo.io.AIPromptGuard.WebhookR\awebhook*C\n" +
	"\rApiJsonSchema\x12\v\n" +
	"\aNOT_SET\x10\x00\x12\r\n" +
	"\tANTHROPIC\x10\x01\x12\n" +
	"\n" +
	"\x06GEMINI\x10\x02\x12\n" +
	"\n" +
	"\x06OPENAI\x10\x03BT\xb8\xf5\x04\x01\xc0\xf5\x04\x01\xd0\xf5\x04\x01ZFgithub.com/solo-io/gloo/projects/gloo/pkg/api/v1/enterprise/options/aib\x06proto3"

var (
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescOnce sync.Once
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescData []byte
)

func file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescGZIP() []byte {
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescOnce.Do(func() {
		file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDesc), len(file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDesc)))
	})
	return file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDescData
}

var file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes = make([]protoimpl.EnumInfo, 7)
var file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes = make([]protoimpl.MessageInfo, 40)
var file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_goTypes = []any{
	(ApiJsonSchema)(0),                               // 0: ai.options.gloo.solo.io.ApiJsonSchema
	(UpstreamSpec_VertexAI_Publisher)(0),             // 1: ai.options.gloo.solo.io.UpstreamSpec.VertexAI.Publisher
	(RouteSettings_RouteType)(0),                     // 2: ai.options.gloo.solo.io.RouteSettings.RouteType
	(SemanticCache_Mode)(0),                          // 3: ai.options.gloo.solo.io.SemanticCache.Mode
	(AIPromptGuard_Regex_BuiltIn)(0),                 // 4: ai.options.gloo.solo.io.AIPromptGuard.Regex.BuiltIn
	(AIPromptGuard_Regex_Action)(0),                  // 5: ai.options.gloo.solo.io.AIPromptGuard.Regex.Action
	(AIPromptGuard_Webhook_HeaderMatch_MatchType)(0), // 6: ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatch.MatchType
	(*SingleAuthToken)(nil),                          // 7: ai.options.gloo.solo.io.SingleAuthToken
	(*UpstreamSpec)(nil),                             // 8: ai.options.gloo.solo.io.UpstreamSpec
	(*RouteSettings)(nil),                            // 9: ai.options.gloo.solo.io.RouteSettings
	(*FieldDefault)(nil),                             // 10: ai.options.gloo.solo.io.FieldDefault
	(*Postgres)(nil),                                 // 11: ai.options.gloo.solo.io.Postgres
	(*Embedding)(nil),                                // 12: ai.options.gloo.solo.io.Embedding
	(*SemanticCache)(nil),                            // 13: ai.options.gloo.solo.io.SemanticCache
	(*RAG)(nil),                                      // 14: ai.options.gloo.solo.io.RAG
	(*AIPromptEnrichment)(nil),                       // 15: ai.options.gloo.solo.io.AIPromptEnrichment
	(*AIPromptGuard)(nil),                            // 16: ai.options.gloo.solo.io.AIPromptGuard
	(*SingleAuthToken_Passthrough)(nil),              // 17: ai.options.gloo.solo.io.SingleAuthToken.Passthrough
	(*UpstreamSpec_CustomHost)(nil),                  // 18: ai.options.gloo.solo.io.UpstreamSpec.CustomHost
	(*UpstreamSpec_OpenAI)(nil),                      // 19: ai.options.gloo.solo.io.UpstreamSpec.OpenAI
	(*UpstreamSpec_AzureOpenAI)(nil),                 // 20: ai.options.gloo.solo.io.UpstreamSpec.AzureOpenAI
	(*UpstreamSpec_Gemini)(nil),                      // 21: ai.options.gloo.solo.io.UpstreamSpec.Gemini
	(*UpstreamSpec_VertexAI)(nil),                    // 22: ai.options.gloo.solo.io.UpstreamSpec.VertexAI
	(*UpstreamSpec_Mistral)(nil),                     // 23: ai.options.gloo.solo.io.UpstreamSpec.Mistral
	(*UpstreamSpec_Anthropic)(nil),                   // 24: ai.options.gloo.solo.io.UpstreamSpec.Anthropic
	(*UpstreamSpec_Bedrock)(nil),                     // 25: ai.options.gloo.solo.io.UpstreamSpec.Bedrock
	(*UpstreamSpec_AwsCredentialProvider)(nil),       // 26: ai.options.gloo.solo.io.UpstreamSpec.AwsCredentialProvider
	(*UpstreamSpec_AWSInline)(nil),                   // 27: ai.options.gloo.solo.io.UpstreamSpec.AWSInline
	(*UpstreamSpec_MultiPool)(nil),                   // 28: ai.options.gloo.solo.io.UpstreamSpec.MultiPool
	(*UpstreamSpec_MultiPool_Backend)(nil),           // 29: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend
	(*UpstreamSpec_MultiPool_Priority)(nil),          // 30: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Priority
	(*Embedding_OpenAI)(nil),                         // 31: ai.options.gloo.solo.io.Embedding.OpenAI
	(*Embedding_AzureOpenAI)(nil),                    // 32: ai.options.gloo.solo.io.Embedding.AzureOpenAI
	(*SemanticCache_Redis)(nil),                      // 33: ai.options.gloo.solo.io.SemanticCache.Redis
	(*SemanticCache_Weaviate)(nil),                   // 34: ai.options.gloo.solo.io.SemanticCache.Weaviate
	(*SemanticCache_DataStore)(nil),                  // 35: ai.options.gloo.solo.io.SemanticCache.DataStore
	(*RAG_DataStore)(nil),                            // 36: ai.options.gloo.solo.io.RAG.DataStore
	(*AIPromptEnrichment_Message)(nil),               // 37: ai.options.gloo.solo.io.AIPromptEnrichment.Message
	(*AIPromptGuard_Regex)(nil),                      // 38: ai.options.gloo.solo.io.AIPromptGuard.Regex
	(*AIPromptGuard_Webhook)(nil),                    // 39: ai.options.gloo.solo.io.AIPromptGuard.Webhook
	(*AIPromptGuard_Moderation)(nil),                 // 40: ai.options.gloo.solo.io.AIPromptGuard.Moderation
	(*AIPromptGuard_Request)(nil),                    // 41: ai.options.gloo.solo.io.AIPromptGuard.Request
	(*AIPromptGuard_Response)(nil),                   // 42: ai.options.gloo.solo.io.AIPromptGuard.Response
	(*AIPromptGuard_Regex_RegexMatch)(nil),           // 43: ai.options.gloo.solo.io.AIPromptGuard.Regex.RegexMatch
	(*AIPromptGuard_Webhook_HeaderMatch)(nil),        // 44: ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatch
	(*AIPromptGuard_Moderation_OpenAI)(nil),          // 45: ai.options.gloo.solo.io.AIPromptGuard.Moderation.OpenAI
	(*AIPromptGuard_Request_CustomResponse)(nil),     // 46: ai.options.gloo.solo.io.AIPromptGuard.Request.CustomResponse
	(*core.ResourceRef)(nil),                         // 47: core.solo.io.ResourceRef
	(*structpb.Value)(nil),                           // 48: google.protobuf.Value
	(*wrapperspb.StringValue)(nil),                   // 49: google.protobuf.StringValue
}
var file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_depIdxs = []int32{
	47, // 0: ai.options.gloo.solo.io.SingleAuthToken.secret_ref:type_name -> core.solo.io.ResourceRef
	17, // 1: ai.options.gloo.solo.io.SingleAuthToken.passthrough:type_name -> ai.options.gloo.solo.io.SingleAuthToken.Passthrough
	19, // 2: ai.options.gloo.solo.io.UpstreamSpec.openai:type_name -> ai.options.gloo.solo.io.UpstreamSpec.OpenAI
	23, // 3: ai.options.gloo.solo.io.UpstreamSpec.mistral:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Mistral
	24, // 4: ai.options.gloo.solo.io.UpstreamSpec.anthropic:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Anthropic
	20, // 5: ai.options.gloo.solo.io.UpstreamSpec.azure_openai:type_name -> ai.options.gloo.solo.io.UpstreamSpec.AzureOpenAI
	28, // 6: ai.options.gloo.solo.io.UpstreamSpec.multi:type_name -> ai.options.gloo.solo.io.UpstreamSpec.MultiPool
	21, // 7: ai.options.gloo.solo.io.UpstreamSpec.gemini:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Gemini
	22, // 8: ai.options.gloo.solo.io.UpstreamSpec.vertex_ai:type_name -> ai.options.gloo.solo.io.UpstreamSpec.VertexAI
	25, // 9: ai.options.gloo.solo.io.UpstreamSpec.bedrock:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Bedrock
	15, // 10: ai.options.gloo.solo.io.RouteSettings.prompt_enrichment:type_name -> ai.options.gloo.solo.io.AIPromptEnrichment
	16, // 11: ai.options.gloo.solo.io.RouteSettings.prompt_guard:type_name -> ai.options.gloo.solo.io.AIPromptGuard
	14, // 12: ai.options.gloo.solo.io.RouteSettings.rag:type_name -> ai.options.gloo.solo.io.RAG
	13, // 13: ai.options.gloo.solo.io.RouteSettings.semantic_cache:type_name -> ai.options.gloo.solo.io.SemanticCache
	10, // 14: ai.options.gloo.solo.io.RouteSettings.defaults:type_name -> ai.options.gloo.solo.io.FieldDefault
	2,  // 15: ai.options.gloo.solo.io.RouteSettings.route_type:type_name -> ai.options.gloo.solo.io.RouteSettings.RouteType
	48, // 16: ai.options.gloo.solo.io.FieldDefault.value:type_name -> google.protobuf.Value
	31, // 17: ai.options.gloo.solo.io.Embedding.openai:type_name -> ai.options.gloo.solo.io.Embedding.OpenAI
	32, // 18: ai.options.gloo.solo.io.Embedding.azure_openai:type_name -> ai.options.gloo.solo.io.Embedding.AzureOpenAI
	35, // 19: ai.options.gloo.solo.io.SemanticCache.datastore:type_name -> ai.options.gloo.solo.io.SemanticCache.DataStore
	12, // 20: ai.options.gloo.solo.io.SemanticCache.embedding:type_name -> ai.options.gloo.solo.io.Embedding
	3,  // 21: ai.options.gloo.solo.io.SemanticCache.mode:type_name -> ai.options.gloo.solo.io.SemanticCache.Mode
	36, // 22: ai.options.gloo.solo.io.RAG.datastore:type_name -> ai.options.gloo.solo.io.RAG.DataStore
	12, // 23: ai.options.gloo.solo.io.RAG.embedding:type_name -> ai.options.gloo.solo.io.Embedding
	37, // 24: ai.options.gloo.solo.io.AIPromptEnrichment.prepend:type_name -> ai.options.gloo.solo.io.AIPromptEnrichment.Message
	37, // 25: ai.options.gloo.solo.io.AIPromptEnrichment.append:type_name -> ai.options.gloo.solo.io.AIPromptEnrichment.Message
	41, // 26: ai.options.gloo.solo.io.AIPromptGuard.request:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Request
	42, // 27: ai.options.gloo.solo.io.AIPromptGuard.response:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Response
	49, // 28: ai.options.gloo.solo.io.UpstreamSpec.CustomHost.hostname:type_name -> google.protobuf.StringValue
	7,  // 29: ai.options.gloo.solo.io.UpstreamSpec.OpenAI.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	18, // 30: ai.options.gloo.solo.io.UpstreamSpec.OpenAI.custom_host:type_name -> ai.options.gloo.solo.io.UpstreamSpec.CustomHost
	7,  // 31: ai.options.gloo.solo.io.UpstreamSpec.AzureOpenAI.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	7,  // 32: ai.options.gloo.solo.io.UpstreamSpec.Gemini.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	7,  // 33: ai.options.gloo.solo.io.UpstreamSpec.VertexAI.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	1,  // 34: ai.options.gloo.solo.io.UpstreamSpec.VertexAI.publisher:type_name -> ai.options.gloo.solo.io.UpstreamSpec.VertexAI.Publisher
	0,  // 35: ai.options.gloo.solo.io.UpstreamSpec.VertexAI.json_schema:type_name -> ai.options.gloo.solo.io.ApiJsonSchema
	7,  // 36: ai.options.gloo.solo.io.UpstreamSpec.Mistral.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	18, // 37: ai.options.gloo.solo.io.UpstreamSpec.Mistral.custom_host:type_name -> ai.options.gloo.solo.io.UpstreamSpec.CustomHost
	7,  // 38: ai.options.gloo.solo.io.UpstreamSpec.Anthropic.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	18, // 39: ai.options.gloo.solo.io.UpstreamSpec.Anthropic.custom_host:type_name -> ai.options.gloo.solo.io.UpstreamSpec.CustomHost
	26, // 40: ai.options.gloo.solo.io.UpstreamSpec.Bedrock.credential_provider:type_name -> ai.options.gloo.solo.io.UpstreamSpec.AwsCredentialProvider
	18, // 41: ai.options.gloo.solo.io.UpstreamSpec.Bedrock.custom_host:type_name -> ai.options.gloo.solo.io.UpstreamSpec.CustomHost
	47, // 42: ai.options.gloo.solo.io.UpstreamSpec.AwsCredentialProvider.secret_ref:type_name -> core.solo.io.ResourceRef
	27, // 43: ai.options.gloo.solo.io.UpstreamSpec.AwsCredentialProvider.inline:type_name -> ai.options.gloo.solo.io.UpstreamSpec.AWSInline
	30, // 44: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.priorities:type_name -> ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Priority
	19, // 45: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.openai:type_name -> ai.options.gloo.solo.io.UpstreamSpec.OpenAI
	23, // 46: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.mistral:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Mistral
	24, // 47: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.anthropic:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Anthropic
	20, // 48: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.azure_openai:type_name -> ai.options.gloo.solo.io.UpstreamSpec.AzureOpenAI
	21, // 49: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.gemini:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Gemini
	22, // 50: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.vertex_ai:type_name -> ai.options.gloo.solo.io.UpstreamSpec.VertexAI
	25, // 51: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend.bedrock:type_name -> ai.options.gloo.solo.io.UpstreamSpec.Bedrock
	29, // 52: ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Priority.pool:type_name -> ai.options.gloo.solo.io.UpstreamSpec.MultiPool.Backend
	7,  // 53: ai.options.gloo.solo.io.Embedding.OpenAI.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	7,  // 54: ai.options.gloo.solo.io.Embedding.AzureOpenAI.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	33, // 55: ai.options.gloo.solo.io.SemanticCache.DataStore.redis:type_name -> ai.options.gloo.solo.io.SemanticCache.Redis
	34, // 56: ai.options.gloo.solo.io.SemanticCache.DataStore.weaviate:type_name -> ai.options.gloo.solo.io.SemanticCache.Weaviate
	11, // 57: ai.options.gloo.solo.io.RAG.DataStore.postgres:type_name -> ai.options.gloo.solo.io.Postgres
	43, // 58: ai.options.gloo.solo.io.AIPromptGuard.Regex.matches:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Regex.RegexMatch
	4,  // 59: ai.options.gloo.solo.io.AIPromptGuard.Regex.builtins:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Regex.BuiltIn
	5,  // 60: ai.options.gloo.solo.io.AIPromptGuard.Regex.action:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Regex.Action
	44, // 61: ai.options.gloo.solo.io.AIPromptGuard.Webhook.forwardHeaders:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatch
	45, // 62: ai.options.gloo.solo.io.AIPromptGuard.Moderation.openai:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Moderation.OpenAI
	46, // 63: ai.options.gloo.solo.io.AIPromptGuard.Request.custom_response:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Request.CustomResponse
	38, // 64: ai.options.gloo.solo.io.AIPromptGuard.Request.regex:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Regex
	39, // 65: ai.options.gloo.solo.io.AIPromptGuard.Request.webhook:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Webhook
	40, // 66: ai.options.gloo.solo.io.AIPromptGuard.Request.moderation:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Moderation
	38, // 67: ai.options.gloo.solo.io.AIPromptGuard.Response.regex:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Regex
	39, // 68: ai.options.gloo.solo.io.AIPromptGuard.Response.webhook:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Webhook
	6,  // 69: ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatch.match_type:type_name -> ai.options.gloo.solo.io.AIPromptGuard.Webhook.HeaderMatch.MatchType
	7,  // 70: ai.options.gloo.solo.io.AIPromptGuard.Moderation.OpenAI.auth_token:type_name -> ai.options.gloo.solo.io.SingleAuthToken
	71, // [71:71] is the sub-list for method output_type
	71, // [71:71] is the sub-list for method input_type
	71, // [71:71] is the sub-list for extension type_name
	71, // [71:71] is the sub-list for extension extendee
	0,  // [0:71] is the sub-list for field type_name
}

func init() { file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_init() }
func file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_init() {
	if File_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto != nil {
		return
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[0].OneofWrappers = []any{
		(*SingleAuthToken_Inline)(nil),
		(*SingleAuthToken_SecretRef)(nil),
		(*SingleAuthToken_Passthrough_)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[1].OneofWrappers = []any{
		(*UpstreamSpec_Openai)(nil),
		(*UpstreamSpec_Mistral_)(nil),
		(*UpstreamSpec_Anthropic_)(nil),
		(*UpstreamSpec_AzureOpenai)(nil),
		(*UpstreamSpec_Multi)(nil),
		(*UpstreamSpec_Gemini_)(nil),
		(*UpstreamSpec_VertexAi)(nil),
		(*UpstreamSpec_Bedrock_)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[5].OneofWrappers = []any{
		(*Embedding_Openai)(nil),
		(*Embedding_AzureOpenai)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[13].OneofWrappers = []any{
		(*UpstreamSpec_AzureOpenAI_AuthToken)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[14].OneofWrappers = []any{
		(*UpstreamSpec_Gemini_AuthToken)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[15].OneofWrappers = []any{
		(*UpstreamSpec_VertexAI_AuthToken)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[19].OneofWrappers = []any{
		(*UpstreamSpec_AwsCredentialProvider_SecretRef)(nil),
		(*UpstreamSpec_AwsCredentialProvider_Inline)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[22].OneofWrappers = []any{
		(*UpstreamSpec_MultiPool_Backend_Openai)(nil),
		(*UpstreamSpec_MultiPool_Backend_Mistral)(nil),
		(*UpstreamSpec_MultiPool_Backend_Anthropic)(nil),
		(*UpstreamSpec_MultiPool_Backend_AzureOpenai)(nil),
		(*UpstreamSpec_MultiPool_Backend_Gemini)(nil),
		(*UpstreamSpec_MultiPool_Backend_VertexAi)(nil),
		(*UpstreamSpec_MultiPool_Backend_Bedrock)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[24].OneofWrappers = []any{
		(*Embedding_OpenAI_AuthToken)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[25].OneofWrappers = []any{
		(*Embedding_AzureOpenAI_AuthToken)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[28].OneofWrappers = []any{
		(*SemanticCache_DataStore_Redis)(nil),
		(*SemanticCache_DataStore_Weaviate)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[29].OneofWrappers = []any{
		(*RAG_DataStore_Postgres)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[33].OneofWrappers = []any{
		(*AIPromptGuard_Moderation_Openai)(nil),
	}
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes[38].OneofWrappers = []any{
		(*AIPromptGuard_Moderation_OpenAI_AuthToken)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDesc), len(file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_rawDesc)),
			NumEnums:      7,
			NumMessages:   40,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_goTypes,
		DependencyIndexes: file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_depIdxs,
		EnumInfos:         file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_enumTypes,
		MessageInfos:      file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_msgTypes,
	}.Build()
	File_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto = out.File
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_goTypes = nil
	file_github_com_solo_io_gloo_projects_gloo_api_v1_enterprise_options_ai_ai_proto_depIdxs = nil
}
